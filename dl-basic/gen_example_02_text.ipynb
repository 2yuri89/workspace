{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\human\\.conda\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tf_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_files/nietzsche.txt\", \"rt\") as f: # rt: read text\n",
    "    nietzche_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\nSUPPOSING that Truth'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( len(nietzche_text) ) # 600893자\n",
    "nietzche_text[:30]  # 대소문자 모두 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preface\\n\\n\\nsupposing that truth'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 대문자 -> 소문자\n",
    "nietzche_lower_text = nietzche_text.lower()\n",
    "nietzche_lower_text[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n' ' ' '!' '\"' \"'\" '(' ')' ',' '-' '.' '0' '1' '2' '3' '4' '5' '6' '7'\n",
      " '8' '9' ':' ';' '=' '?' '[' ']' '_' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i'\n",
      " 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z' 'ä'\n",
      " 'æ' 'é' 'ë']\n",
      "(57,)\n"
     ]
    }
   ],
   "source": [
    "# 전체 텍스트에 포함된 문자 확인\n",
    "print( np.unique(list(nietzche_lower_text)) )\n",
    "print( np.unique(list(nietzche_lower_text)).shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합 > ['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ä', 'æ', 'é', 'ë']\n",
      "문자:숫자 > {'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, '8': 18, '9': 19, ':': 20, ';': 21, '=': 22, '?': 23, '[': 24, ']': 25, '_': 26, 'a': 27, 'b': 28, 'c': 29, 'd': 30, 'e': 31, 'f': 32, 'g': 33, 'h': 34, 'i': 35, 'j': 36, 'k': 37, 'l': 38, 'm': 39, 'n': 40, 'o': 41, 'p': 42, 'q': 43, 'r': 44, 's': 45, 't': 46, 'u': 47, 'v': 48, 'w': 49, 'x': 50, 'y': 51, 'z': 52, 'ä': 53, 'æ': 54, 'é': 55, 'ë': 56}\n",
      "숫자:문자 > {0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: \"'\", 5: '(', 6: ')', 7: ',', 8: '-', 9: '.', 10: '0', 11: '1', 12: '2', 13: '3', 14: '4', 15: '5', 16: '6', 17: '7', 18: '8', 19: '9', 20: ':', 21: ';', 22: '=', 23: '?', 24: '[', 25: ']', 26: '_', 27: 'a', 28: 'b', 29: 'c', 30: 'd', 31: 'e', 32: 'f', 33: 'g', 34: 'h', 35: 'i', 36: 'j', 37: 'k', 38: 'l', 39: 'm', 40: 'n', 41: 'o', 42: 'p', 43: 'q', 44: 'r', 45: 's', 46: 't', 47: 'u', 48: 'v', 49: 'w', 50: 'x', 51: 'y', 52: 'z', 53: 'ä', 54: 'æ', 55: 'é', 56: 'ë'}\n"
     ]
    }
   ],
   "source": [
    "# 문자 사전 만들기\n",
    "\n",
    "set(nietzche_lower_text)\n",
    "# set : 중복되지 않는 리스트\n",
    "sorted_chars = sorted(set(nietzche_lower_text))\n",
    "print( \"단어 집합 >\", sorted_chars )\n",
    "\n",
    "# 정렬된 문자 앞부터 0으로 메기기 시작\n",
    "char_to_idx = { ch:i for i, ch in enumerate(sorted_chars) } # 문자 : 숫자\n",
    "print( \"문자:숫자 >\", char_to_idx )\n",
    "\n",
    "idx_to_char = { i:ch for ch, i in char_to_idx.items() }     # 숫자 : 문자 (char_to_idx를 반전)\n",
    "print( \"숫자:문자 >\", idx_to_char )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 내용\n",
    "\n",
    "# n개의 연속된 문자 -> n+1번째 문자 예측\n",
    "# (입력데이터)         (출력데이터, target)\n",
    "# n개의 연속된 문자를 이용해서, n+1번째 1개의 문자 예측하기\n",
    "# 단어라면 함축적 의미를 가지니 여려군데서 의미 달라질 수 있어서 임베딩처리가 마땅하지만,\n",
    "# 문자는 임베딩처리하지 않고 단어 사전 수준에서 작업\n",
    "# 문자가 단어사전 수준으로 하더라도 속성이 57개 뿐이라 가능하겠군.\n",
    "# 원핫인코딩 단어사전을 가지고 작업할 예정이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 준비\n",
    "\n",
    "sequence_length = 50    # 연속된 문자의 개수\n",
    "step = 3                # stride (3문자씩 이동하면서 데이터 추출) : 다음 입력 데이터를 만들 때 3개 띈다\n",
    "\n",
    "sequences = []        # (batch_size, 입력문자개수, 단어사전크기)\n",
    "next_chars = []         # (batch_size, 단어사전크기) 한 개 예측 되는 문자\n",
    "\n",
    "# 50개 + 1개 > 51개\n",
    "for idx in range(0, len(nietzche_lower_text) - sequence_length, step):\n",
    "    sequences.append(nietzche_lower_text[idx:idx+sequence_length])\n",
    "    next_chars.append(nietzche_lower_text[idx+sequence_length]) # 다음 예측할 문자\n",
    "\n",
    "# print( len(sequences), len(next_chars) )\n",
    "# print( sequences[0], next_chars[0] )\n",
    "# 입력 : supposing that truth is a woman--what th, 출력 : e > 숫자로 바꿔야한다.\n",
    "\n",
    "X = np.zeros(shape=(len(sequences), sequence_length, len(sorted_chars)))\n",
    "# 데이터를 다 0으로 채워넣고 문자있으면 반복문 돌면서 1로 체크\n",
    "y = np.zeros(shape=(len(sequences), len(sorted_chars)))\n",
    "\n",
    "for si, sequence in enumerate(sequences):   # si : 입력 문장 순서 번호\n",
    "    # print(si, sequence)\n",
    "    for ci, ch in enumerate(sequence):      # ci : 한 개의 입력 문장 안의 문자 순서 번호\n",
    "        X[si, ci, char_to_idx[ch]] = 1      # 문장 번호 안에서 각 문자를 돌면서, 있는 문자에 1을 넣는다\n",
    "        y[si, char_to_idx[next_chars[si]]] = 1\n",
    "        # print(ci, ch, end=\", \")\n",
    "    # if si == 2:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\human\\.conda\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 50, 57)]          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               95232     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 57)                7353      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102585 (400.72 KB)\n",
      "Trainable params: 102585 (400.72 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구조 설계 (순환 신경망)\n",
    "\n",
    "input = tf_keras.layers.Input(shape=(sequence_length, len(sorted_chars)))\n",
    "x = tf_keras.layers.LSTM(units=128)(input)\n",
    "output = tf_keras.layers.Dense(units=len(sorted_chars), activation='softmax')(x)\n",
    "# 회귀 아닌 분류 그래서 마지막 유닛수는 분류하는 카테고리 수 만큼 (단어사전 크기)\n",
    "model = tf_keras.models.Model(input, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-dl-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
