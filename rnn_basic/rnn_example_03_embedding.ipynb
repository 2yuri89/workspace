{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tf_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf_keras.utils.text_dataset_from_directory(\"data_files/aclImdb/train\", batch_size=32)\n",
    "test_dataset = tf_keras.utils.text_dataset_from_directory('data_files/aclImdb/test', batch_size=32)\n",
    "\n",
    "# review_only_dataset = train_datasest.map(lambda X, y: X)\n",
    "review_only_dataset = train_dataset.map(lambda review, label: review)\n",
    "# train_dataset에 review와 label 있는데, 그중에서 reivew만 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.batch_op._BatchDataset"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32,) (32,)\n",
      "tf.Tensor(b'Blood Surf AKA Krocodylus is a fair film that has an okay cast which includes Dax Miller, Taryn Reif, Kate Fischer, Duncan Regehr, Joel West, Matt Borlenghi, Maureen Larrazabal, Cris Vertido, Susan Africa, Archie Adamos, Rolando Santo Domingo, and Malecio Amayao. The acting by the actors is fairly good. The thrills are fairly good and some of it is surprising. The movie is filmed fairly good as well. Same thing goes for the music The film is fairly interesting and the movie does keeps you going until the end. This is a fairly thrilling film. If you the the cast in the film, Monsters, Giant Animal films, Horror, Thrillers, Mystery, and interesting films then I recommend you to see this film today!', shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dataset: # review를 X로, label을 y로 받음\n",
    "    print(X.shape, y.shape)\n",
    "    print(X[0])\n",
    "    print(y[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\human\\.conda\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\human\\.conda\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 문장(보통 document라 함. ) (단어 집합) -> 숫자 집합 : encoding\n",
    "# max_tokens=단어 사전 크기 혹은 총 단어 개수다. 이걸 넘는 단어는 '모르는 단어' 취급함\n",
    "# output_mode = 출력 유형\n",
    "# output_sequence_length = 한 문장에 들어가는 단어 수. 모자르면 패딩, 넘으면 자름\n",
    "text_vectorizer = tf_keras.layers.TextVectorization(max_tokens=20000, \n",
    "                                                    output_mode='int', \n",
    "                                                    output_sequence_length=300)\n",
    "\n",
    "text_vectorizer.adapt(review_only_dataset)\n",
    "# review_only_dataset 이 데이터를 가지고 변환기(vectorizer)에 단어 사전 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 300)\n",
      "tf.Tensor(\n",
      "[[  57 1198  132 ...    0    0    0]\n",
      " [  86    6  856 ...   15    4  812]\n",
      " [  84  225   84 ...    0    0    0]\n",
      " ...\n",
      " [2452 1360   20 ...    0    0    0]\n",
      " [   8    2 2346 ...    0    0    0]\n",
      " [  11   44  203 ...    0    0    0]], shape=(32, 300), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# (문장 -> 숫자 리스트) 변환기 테스트\n",
    "for X, y in train_dataset:\n",
    "    d = text_vectorizer(X)  # 변환 실행 [X: (32, 1) -> X: (32, 300)]\n",
    "    # batch_size=32라서 X는 32문장이 나오는데, 위에서 한 문장당 300 단어 (정확히는 토큰) 쓰기로 했음\n",
    "    print(d.shape)\n",
    "    print(d)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i', 'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 사전 확인\n",
    "dictionary = text_vectorizer.get_vocabulary()\n",
    "print(len(dictionary))\n",
    "# 단어 사전에 없는 단어 표시 : UNK(unknown) (혹은 oov (out of vocabulary))\n",
    "dictionary[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  86    6  856    1   13  527  934   56 1336   86   10  153  888]\n",
      "first to die [UNK] br ill admit my mistake first i didnt realize this was a made for tv movie i was thrown off by the r [UNK] the plot is strong but the movie is about 40 minutes too long the direction and continuity were excellent for the most part the cast was exceptional and did a good job with their characters the down side of the movie is that it definitely falls into the chick flick genre although there are some violent scenes none of the violence should call for an r rating there is no nudity or gratuitous sex scenes actually there are no sex scenes [UNK] [UNK] who is absolutely beautiful [UNK] [UNK] [UNK] [UNK] and [UNK] davies were all guests on the sg1 series but this movie did nothing to advance their careers since they were all used as low level supporting actresses robert patrick was fantastic as he usually is and mitch [UNK] made me think of a modern day lee marvin the very talented megan [UNK] who i came to respect as an actor during the millennium series was given nothing challenging to show her range of abilities the greatest disappointment with regard to the cast was tracy [UNK] aside from being a below average actress and not particularly attractive her voice is absolutely annoying i found myself [UNK] the tv during her dialogue i would recommend this movie to anyone who enjoys the lifetime tv type of programs i would not recommend paying any money to see this movie however considering i found nothing that would cause censorship this is a movie that is worthy for only watching on tv since nothing will be cut out as a tv movie i would rate this as a 5 out 10 as a feature "
     ]
    }
   ],
   "source": [
    "# 숫자로 인코딩된 문장을 원래 문장으로 복원\n",
    "print(d[1][:13].numpy())    # .numpy()를 붙이면 숫자만 볼 수 있다.\n",
    "for t in d[1]:\n",
    "    if t != 0:\n",
    "        print(dictionary[t], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding 모델 만들기 : 단어(토큰을 벡터로 만드는 모델) # 벡터 여러개의 데이터\n",
    "# 얘만 가지고 뭘 하진 못하고 이걸 만들어서 학습 과정에 넣어줘야한다.\n",
    "\n",
    "input = tf_keras.layers.Input(shape=(None, ))\n",
    "# input_dim = 단어 사전, output_dim = 단어 하나가 가질 의미의 수\n",
    "output = tf_keras.layers.Embedding(input_dim=20000, output_dim=100)(input)\n",
    "\n",
    "embedding_model = tf_keras.models.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review in review_only_dataset:\n",
    "    # print(review)\n",
    "    vectorized_review = text_vectorizer(review)                 # 단어 1개 -> 숫자 1개\n",
    "    # embedded_review = embedding_model(text_vectorizer(review))# 단어 1개 -> 숫자 100개\n",
    "    embedded_review = embedding_model(vectorized_review)        # 숫자 1개 -> 숫자 100개 \n",
    "    break\n",
    "# text_vectorizer(review) 이걸 한 뒤 변환된 출력을 embedding_model의 입력으로 받는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 300]), TensorShape([32, 300, 100]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_review.shape, embedded_review.shape\n",
    "# (TensorShape([32, 300]), TensorShape([32, 300, 100]))\n",
    "# 이걸 활용해서 문맥에 따라 서로 다른 정보를 가질 수 있도록 넓은 공간에 데이터를 저장하는 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터의 모든 문자열(리뷰)을 숫자로 변경\n",
    "# 리뷰는 텍스트 벡터라이저를 통해 수치화한다.\n",
    "vectorized_train_dataset = train_dataset.map(lambda review, label: (text_vectorizer(review), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 131   11    7 ...    0    0    0]\n",
      " [ 147    9  457 ...    0    0    0]\n",
      " [1210 1492 1770 ...  287  560 8370]\n",
      " ...\n",
      " [  10  237  485 ...    0    0    0]\n",
      " [7925    7   22 ...    0    0    0]\n",
      " [  15  513   15 ...    0    0    0]], shape=(32, 300), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 변경 확인\n",
    "for X, y in vectorized_train_dataset:\n",
    "    print(X)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, None, 100)         2000000   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 16)                7488      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2007505 (7.66 MB)\n",
      "Trainable params: 2007505 (7.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구조 설계 : 텍스트 데이터 처리를 위한 순환신경망 모델\n",
    "\n",
    "input = tf_keras.layers.Input(shape=(None,))\n",
    "x = tf_keras.layers.Embedding(input_dim=20000, output_dim=100)(input)   # None, 300, 100\n",
    "x = tf_keras.layers.LSTM(units=16)(x)\n",
    "output = tf_keras.layers.Dense(units=1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf_keras.models.Model(input, output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 설계\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 76s 95ms/step - loss: 0.6837 - accuracy: 0.5398\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 74s 94ms/step - loss: 0.6588 - accuracy: 0.5956\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 71s 91ms/step - loss: 0.6408 - accuracy: 0.5842\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 73s 93ms/step - loss: 0.5976 - accuracy: 0.6006\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 72s 91ms/step - loss: 0.5645 - accuracy: 0.6236\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 72s 92ms/step - loss: 0.4607 - accuracy: 0.7962\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 77s 98ms/step - loss: 0.4443 - accuracy: 0.8045\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 92s 117ms/step - loss: 0.4321 - accuracy: 0.8104\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 71s 91ms/step - loss: 0.4204 - accuracy: 0.8150\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 70s 89ms/step - loss: 0.3638 - accuracy: 0.8395\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "fit_history = model.fit(vectorized_train_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-dl-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
