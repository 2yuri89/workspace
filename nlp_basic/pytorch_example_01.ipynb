{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch (데이터, 모델)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pytorch\n",
    "# ! pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision  # cnn 계열 도구\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# GPU 사용 가능 여부 확인 -> GPU, CPU 선택\n",
    "\n",
    "if torch.cuda.is_available():   # False\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "# gpu가 가능하다면, gpu를 사용하고, 그렇지 않다면 cpu를 사용한다.\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비 1. \n",
    "\n",
    "# 기존 tensorflow 쓸 때 방식의 예시 : tf_keras.datasets.mnist.load_data()\n",
    "# tensorflow에서는 generator 사용했음 (cnn03 : dogs and cats) > generator로 dataset 구성함\n",
    "transform =  transforms.Compose([transforms.ToTensor()])\n",
    "# transforms : 이미지 변환기, Compose : 변환기 모아서 작업, \n",
    "# 이미지 증강위한 도구들 : CenterCrop, RandomCrop, 등\n",
    "# ToTensor() : 텐서로 변환하는 작업\n",
    "# tnesor는 다차원 배열 + 딥러닝이 요구하는 데이터 처리 기본 기능이 있는 애. \n",
    "# 대표적으로 오차역전파 같은거 자동으로 처리 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비 2. (데이터셋 만들기)\n",
    "train_dataset = datasets.MNIST(root=\"data_files\", \n",
    "                               train=True, \n",
    "                               download=True, \n",
    "                            #    transform=transforms.ToTensor(),\n",
    "                               transform=transform)\n",
    "# datasets: torchvision의 내장 datasets 사용하기\n",
    "# (root=\"data_files/MNIST\")  : 데이터셋 저장 경로 지정\n",
    "# transform=transforms.ToTensor() 로 직접 지정해도 된다.\n",
    "test_dataset = datasets.MNIST(root=\"data_files\", \n",
    "                              train=False, \n",
    "                              download=True, \n",
    "                              # transform=transforms.ToTensor(),\n",
    "                              transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비 3. (DataLoader)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=32, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=32, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "\n",
    "for X, y in train_loader:\n",
    "    print(X.shape, y.shape)\n",
    "    break\n",
    "# torch.Size([32, 1, 28, 28]) (> channer first 방식), torch.Size([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 5, 4, 9, 9, 1, 2, 7, 6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx in range(10):\n",
    "    plt.subplot(1, 10, idx+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X[idx, :, :, :].reshape(28, 28), cmap='gray_r')\n",
    "plt.show()\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구조 설계\n",
    "\n",
    "class MnistNet(nn.Module):\n",
    "    # 여기서 층을 만들고 ( 모델 구조 설계 1 )\n",
    "    def __init__(self):     # __init__ 초기화 함수. \n",
    "        super(MnistNet, self).__init__()    # 꼭 부모 클래스호출. 부모 클래스한테 내가 누군지 알려주기. \n",
    "        self.fc1 = nn.Linear(28*28, 512)    # fully connected = tonsorflow의 Dense. 입력 28*28, 출력 512\n",
    "        self.fc2 = nn.Linear(512, 256)      # 앞의 출력이 지금의 입력, 출력 256\n",
    "        self.fc3 = nn.Linear(256, 10)       # 마지막 출력층은 클래스 수와 같아야한다.\n",
    "        pass\n",
    "    # 여기서 층을 호출 ( 모델 구조 설계 2 )\n",
    "    def forward(self, x):   # forward 여기서 모델 훈련. 그래서 입력데이터 받아주는 전달인자 필요\n",
    "    # view는 numpy의 reshape과 유사. 기능만보면, tensorflow의 flattne(무조건 1차원으로 변환)과 유사. \n",
    "    # (view는 무조건 1차원으로 바꾸는건 아님)\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)               # activation 지정: sigmoid, relu, selu, elu 등\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim=1) # dim=1: 손실함수 계산하는 방법 지정\n",
    "        return x                    # 연산 끝난 x 받기\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistNet(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 학습 도구 구성\n",
    "model = MnistNet().to(device)\n",
    "# loss = nn.CrossEntropyLoss()      # 카테고리 분류시 사용할 손실함수\n",
    "criterion = nn.CrossEntropyLoss()     # torch 사용자들은 loss보다 criterion이라고 사용\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # learning late(lr) 기본값 0.001\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 함수 정의 (학습 도구 기반 학습 설계) ( 함수 안 만들고 쭉 써도 된다. ) (tensorflow의 fit)\n",
    "def train(model, train_loader, optimizer):\n",
    "    model.train()   # train mode로 설정 > '지금부터 훈련이니까 가중치 업뎃 잘 해줘'라는 의미\n",
    "    # 얘는 이 작업을 cpu에서 할지 gpu에서 할 지 알려줘야해\n",
    "    # 모델이 gpu면 데이터도 gpu, 모델이 cpu면 데이터도 cpu\n",
    "    for idx, (images, labels) in enumerate(train_loader):   # 훈련 log위해서 idx enumerate 설정\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()               # optimizer 초기화\n",
    "        output = model(images)              # 모델이 학습할 images 주기\n",
    "        loss = criterion(output, labels)    # 손실 계산을 위한 계산값과 실제값\n",
    "        loss.backward()                     # 손실을 이용해서 기울기 계산(미분 작업 수행)\n",
    "        optimizer.step()                    # optimizer가 가중치 업데이트 하라는 것\n",
    "\n",
    "        if idx % 10 == 0:       # 10번에 한 번씩 log 남기기\n",
    "            print(f'Batch : {idx}, Loss : {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 함수 정의 2 (배치 10으로 하니 너무 많아서 300으로 조정)\n",
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for idx, (images, labels) in enumerate(train_loader):   # 훈련 log위해서 idx enumerate 설정\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()               # optimizer 초기화\n",
    "        output = model(images)              # 모델이 학습할 images 주기\n",
    "        loss = criterion(output, labels)    # 손실 계산을 위한 계산값과 실제값\n",
    "        loss.backward()                     # 손실을 이용해서 기울기 계산(미분 작업 수행)\n",
    "        optimizer.step()                    # optimizer가 가중치 업데이트 하라는 것\n",
    "\n",
    "        if idx % 300 == 0:       # 10번에 한 번씩 log 남기기\n",
    "            print(f'Batch : {idx}, Loss : {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 함수 정의\n",
    "def evaluate(model, test_loader):\n",
    "    loss_total = 0      # 전체 로스 한꺼번에 처리\n",
    "    correct_total = 0\n",
    "    model.eval()    # evaluation 모드로 설정 -> batch-normalization, drop-out 수행 중지\n",
    "    with torch.no_grad():   # 가중치 업데이트 수행 중지 (기울기 계산 하지 마라)\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels).item() # item: tensor 안에 들어있는 값을 가져오기\n",
    "            loss_total += loss\n",
    "            predicted_values = output.max(1, keepdim=True)[1]   # output에서 max 1개 값만 가져오기\n",
    "            correct = predicted_values.eq(labels.view_as(predicted_values)).sum().item() # 비교하기\n",
    "            correct_total += correct\n",
    "    \n",
    "    loss_total /= (len(test_dataset) / 32 )\n",
    "    # loss_total은 배치마다 나오므로, 전체 데이터셋을 배치사이즈로 나눈 값을 나눈 것\n",
    "    accuracy = correct_total / len(test_dataset)\n",
    "    # correct는 배치로 하지않고 전체로 했으므로 전체 개수로만 나눈다.\n",
    "\n",
    "    return loss_total, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch : 0, Loss : 2.313100576400757\n",
      "Batch : 10, Loss : 1.8756253719329834\n",
      "Batch : 20, Loss : 1.3719195127487183\n",
      "Batch : 30, Loss : 0.7485756278038025\n",
      "Batch : 40, Loss : 0.7007478475570679\n",
      "Batch : 50, Loss : 0.6945644021034241\n",
      "Batch : 60, Loss : 0.5126047730445862\n",
      "Batch : 70, Loss : 0.6539045572280884\n",
      "Batch : 80, Loss : 0.3862488269805908\n",
      "Batch : 90, Loss : 0.43053779006004333\n",
      "Batch : 100, Loss : 0.28252342343330383\n",
      "Batch : 110, Loss : 0.35779446363449097\n",
      "Batch : 120, Loss : 0.35499492287635803\n",
      "Batch : 130, Loss : 0.3869340717792511\n",
      "Batch : 140, Loss : 0.2716469168663025\n",
      "Batch : 150, Loss : 0.49868443608283997\n",
      "Batch : 160, Loss : 0.4863290786743164\n",
      "Batch : 170, Loss : 0.4904761016368866\n",
      "Batch : 180, Loss : 0.19175484776496887\n",
      "Batch : 190, Loss : 0.42203277349472046\n",
      "Batch : 200, Loss : 0.3434264361858368\n",
      "Batch : 210, Loss : 0.3815877139568329\n",
      "Batch : 220, Loss : 0.23364000022411346\n",
      "Batch : 230, Loss : 0.15688279271125793\n",
      "Batch : 240, Loss : 0.18675777316093445\n",
      "Batch : 250, Loss : 0.22775596380233765\n",
      "Batch : 260, Loss : 0.29215848445892334\n",
      "Batch : 270, Loss : 0.11028314381837845\n",
      "Batch : 280, Loss : 0.2743065655231476\n",
      "Batch : 290, Loss : 0.1537638008594513\n",
      "Batch : 300, Loss : 0.21210099756717682\n",
      "Batch : 310, Loss : 0.4473133385181427\n",
      "Batch : 320, Loss : 0.25176623463630676\n",
      "Batch : 330, Loss : 0.18023332953453064\n",
      "Batch : 340, Loss : 0.15598128736019135\n",
      "Batch : 350, Loss : 0.0728444755077362\n",
      "Batch : 360, Loss : 0.0814642384648323\n",
      "Batch : 370, Loss : 0.47225165367126465\n",
      "Batch : 380, Loss : 0.10997065901756287\n",
      "Batch : 390, Loss : 0.18134574592113495\n",
      "Batch : 400, Loss : 0.3413003385066986\n",
      "Batch : 410, Loss : 0.24253910779953003\n",
      "Batch : 420, Loss : 0.31874823570251465\n",
      "Batch : 430, Loss : 0.042117029428482056\n",
      "Batch : 440, Loss : 0.44063571095466614\n",
      "Batch : 450, Loss : 0.24618011713027954\n",
      "Batch : 460, Loss : 0.24433349072933197\n",
      "Batch : 470, Loss : 0.03720678389072418\n",
      "Batch : 480, Loss : 0.17633399367332458\n",
      "Batch : 490, Loss : 0.19510403275489807\n",
      "Batch : 500, Loss : 0.04191362485289574\n",
      "Batch : 510, Loss : 0.04370933398604393\n",
      "Batch : 520, Loss : 0.05376102775335312\n",
      "Batch : 530, Loss : 0.10357651859521866\n",
      "Batch : 540, Loss : 0.35035666823387146\n",
      "Batch : 550, Loss : 0.32514986395835876\n",
      "Batch : 560, Loss : 0.2720320224761963\n",
      "Batch : 570, Loss : 0.32048994302749634\n",
      "Batch : 580, Loss : 0.2121761590242386\n",
      "Batch : 590, Loss : 0.1753493845462799\n",
      "Batch : 600, Loss : 0.03402084857225418\n",
      "Batch : 610, Loss : 0.10997503995895386\n",
      "Batch : 620, Loss : 0.2758511006832123\n",
      "Batch : 630, Loss : 0.05561693385243416\n",
      "Batch : 640, Loss : 0.13461610674858093\n",
      "Batch : 650, Loss : 0.04597697779536247\n",
      "Batch : 660, Loss : 0.0847158208489418\n",
      "Batch : 670, Loss : 0.111787348985672\n",
      "Batch : 680, Loss : 0.19686520099639893\n",
      "Batch : 690, Loss : 0.1659957766532898\n",
      "Batch : 700, Loss : 0.1334516406059265\n",
      "Batch : 710, Loss : 0.2756667137145996\n",
      "Batch : 720, Loss : 0.2198774367570877\n",
      "Batch : 730, Loss : 0.07192683964967728\n",
      "Batch : 740, Loss : 0.4145992398262024\n",
      "Batch : 750, Loss : 0.06385397166013718\n",
      "Batch : 760, Loss : 0.23984968662261963\n",
      "Batch : 770, Loss : 0.25360316038131714\n",
      "Batch : 780, Loss : 0.2536705732345581\n",
      "Batch : 790, Loss : 0.11664886772632599\n",
      "Batch : 800, Loss : 0.08490662276744843\n",
      "Batch : 810, Loss : 0.08486533164978027\n",
      "Batch : 820, Loss : 0.08644691109657288\n",
      "Batch : 830, Loss : 0.23748725652694702\n",
      "Batch : 840, Loss : 0.18368390202522278\n",
      "Batch : 850, Loss : 0.08356364816427231\n",
      "Batch : 860, Loss : 0.1614212989807129\n",
      "Batch : 870, Loss : 0.249399796128273\n",
      "Batch : 880, Loss : 0.18749864399433136\n",
      "Batch : 890, Loss : 0.10804861783981323\n",
      "Batch : 900, Loss : 0.3591737747192383\n",
      "Batch : 910, Loss : 0.04415129870176315\n",
      "Batch : 920, Loss : 0.13502997159957886\n",
      "Batch : 930, Loss : 0.013536831364035606\n",
      "Batch : 940, Loss : 0.08716196566820145\n",
      "Batch : 950, Loss : 0.06136264652013779\n",
      "Batch : 960, Loss : 0.10019055753946304\n",
      "Batch : 970, Loss : 0.16294685006141663\n",
      "Batch : 980, Loss : 0.08670489490032196\n",
      "Batch : 990, Loss : 0.06522940844297409\n",
      "Batch : 1000, Loss : 0.11231160163879395\n",
      "Batch : 1010, Loss : 0.045976027846336365\n",
      "Batch : 1020, Loss : 0.17753100395202637\n",
      "Batch : 1030, Loss : 0.09989749640226364\n",
      "Batch : 1040, Loss : 0.06039797514677048\n",
      "Batch : 1050, Loss : 0.15711884200572968\n",
      "Batch : 1060, Loss : 0.2724437713623047\n",
      "Batch : 1070, Loss : 0.01883849687874317\n",
      "Batch : 1080, Loss : 0.08689867705106735\n",
      "Batch : 1090, Loss : 0.11830882728099823\n",
      "Batch : 1100, Loss : 0.20409800112247467\n",
      "Batch : 1110, Loss : 0.042420074343681335\n",
      "Batch : 1120, Loss : 0.04146518185734749\n",
      "Batch : 1130, Loss : 0.3303815722465515\n",
      "Batch : 1140, Loss : 0.021394414827227592\n",
      "Batch : 1150, Loss : 0.17490217089653015\n",
      "Batch : 1160, Loss : 0.11205105483531952\n",
      "Batch : 1170, Loss : 0.06520324945449829\n",
      "Batch : 1180, Loss : 0.06297306716442108\n",
      "Batch : 1190, Loss : 0.19170328974723816\n",
      "Batch : 1200, Loss : 0.22968639433383942\n",
      "Batch : 1210, Loss : 0.03063504584133625\n",
      "Batch : 1220, Loss : 0.08485282212495804\n",
      "Batch : 1230, Loss : 0.1697387546300888\n",
      "Batch : 1240, Loss : 0.059643812477588654\n",
      "Batch : 1250, Loss : 0.18035443127155304\n",
      "Batch : 1260, Loss : 0.1694476157426834\n",
      "Batch : 1270, Loss : 0.11672987043857574\n",
      "Batch : 1280, Loss : 0.1353582888841629\n",
      "Batch : 1290, Loss : 0.06188352778553963\n",
      "Batch : 1300, Loss : 0.032346211373806\n",
      "Batch : 1310, Loss : 0.20740637183189392\n",
      "Batch : 1320, Loss : 0.06997321546077728\n",
      "Batch : 1330, Loss : 0.1276027411222458\n",
      "Batch : 1340, Loss : 0.14890238642692566\n",
      "Batch : 1350, Loss : 0.0935768261551857\n",
      "Batch : 1360, Loss : 0.08818888664245605\n",
      "Batch : 1370, Loss : 0.4092545509338379\n",
      "Batch : 1380, Loss : 0.09150028228759766\n",
      "Batch : 1390, Loss : 0.18190239369869232\n",
      "Batch : 1400, Loss : 0.10041455924510956\n",
      "Batch : 1410, Loss : 0.1485920399427414\n",
      "Batch : 1420, Loss : 0.137285515666008\n",
      "Batch : 1430, Loss : 0.04792056232690811\n",
      "Batch : 1440, Loss : 0.044454995542764664\n",
      "Batch : 1450, Loss : 0.3718123435974121\n",
      "Batch : 1460, Loss : 0.061563603579998016\n",
      "Batch : 1470, Loss : 0.16785214841365814\n",
      "Batch : 1480, Loss : 0.03351845592260361\n",
      "Batch : 1490, Loss : 0.05844339728355408\n",
      "Batch : 1500, Loss : 0.07316524535417557\n",
      "Batch : 1510, Loss : 0.16537612676620483\n",
      "Batch : 1520, Loss : 0.06519122421741486\n",
      "Batch : 1530, Loss : 0.21379715204238892\n",
      "Batch : 1540, Loss : 0.06421809643507004\n",
      "Batch : 1550, Loss : 0.009420162066817284\n",
      "Batch : 1560, Loss : 0.12194419652223587\n",
      "Batch : 1570, Loss : 0.06404977291822433\n",
      "Batch : 1580, Loss : 0.0934191644191742\n",
      "Batch : 1590, Loss : 0.2029353529214859\n",
      "Batch : 1600, Loss : 0.034485917538404465\n",
      "Batch : 1610, Loss : 0.14354504644870758\n",
      "Batch : 1620, Loss : 0.029641522094607353\n",
      "Batch : 1630, Loss : 0.09077838063240051\n",
      "Batch : 1640, Loss : 0.16923478245735168\n",
      "Batch : 1650, Loss : 0.23562465608119965\n",
      "Batch : 1660, Loss : 0.012342480942606926\n",
      "Batch : 1670, Loss : 0.04044584557414055\n",
      "Batch : 1680, Loss : 0.2782452404499054\n",
      "Batch : 1690, Loss : 0.03717156872153282\n",
      "Batch : 1700, Loss : 0.05349129065871239\n",
      "Batch : 1710, Loss : 0.04225192591547966\n",
      "Batch : 1720, Loss : 0.2836903929710388\n",
      "Batch : 1730, Loss : 0.13466021418571472\n",
      "Batch : 1740, Loss : 0.2819933295249939\n",
      "Batch : 1750, Loss : 0.207939013838768\n",
      "Batch : 1760, Loss : 0.27064093947410583\n",
      "Batch : 1770, Loss : 0.020403388887643814\n",
      "Batch : 1780, Loss : 0.08381067216396332\n",
      "Batch : 1790, Loss : 0.15413425862789154\n",
      "Batch : 1800, Loss : 0.012803560122847557\n",
      "Batch : 1810, Loss : 0.05339480936527252\n",
      "Batch : 1820, Loss : 0.06195225566625595\n",
      "Batch : 1830, Loss : 0.047870345413684845\n",
      "Batch : 1840, Loss : 0.022202143445611\n",
      "Batch : 1850, Loss : 0.10902433097362518\n",
      "Batch : 1860, Loss : 0.0382741317152977\n",
      "Batch : 1870, Loss : 0.03971618786454201\n",
      "Epoch : 0\n",
      "Batch : 0, Loss : 0.09848467260599136\n",
      "Batch : 10, Loss : 0.0737331435084343\n",
      "Batch : 20, Loss : 0.10621064901351929\n",
      "Batch : 30, Loss : 0.08359978348016739\n",
      "Batch : 40, Loss : 0.05547379329800606\n",
      "Batch : 50, Loss : 0.2166479378938675\n",
      "Batch : 60, Loss : 0.1009288877248764\n",
      "Batch : 70, Loss : 0.050551265478134155\n",
      "Batch : 80, Loss : 0.12890613079071045\n",
      "Batch : 90, Loss : 0.020291481167078018\n",
      "Batch : 100, Loss : 0.014777062460780144\n",
      "Batch : 110, Loss : 0.2689535617828369\n",
      "Batch : 120, Loss : 0.05355340242385864\n",
      "Batch : 130, Loss : 0.05438670888543129\n",
      "Batch : 140, Loss : 0.07300576567649841\n",
      "Batch : 150, Loss : 0.009715937077999115\n",
      "Batch : 160, Loss : 0.13152892887592316\n",
      "Batch : 170, Loss : 0.020966127514839172\n",
      "Batch : 180, Loss : 0.019269416108727455\n",
      "Batch : 190, Loss : 0.03667660430073738\n",
      "Batch : 200, Loss : 0.0037335262168198824\n",
      "Batch : 210, Loss : 0.10117390751838684\n",
      "Batch : 220, Loss : 0.08498960733413696\n",
      "Batch : 230, Loss : 0.11698628216981888\n",
      "Batch : 240, Loss : 0.04458077624440193\n",
      "Batch : 250, Loss : 0.035876281559467316\n",
      "Batch : 260, Loss : 0.1023409515619278\n",
      "Batch : 270, Loss : 0.12403617054224014\n",
      "Batch : 280, Loss : 0.029283633455634117\n",
      "Batch : 290, Loss : 0.27479881048202515\n",
      "Batch : 300, Loss : 0.016002925112843513\n",
      "Batch : 310, Loss : 0.09984878450632095\n",
      "Batch : 320, Loss : 0.2174697071313858\n",
      "Batch : 330, Loss : 0.169644296169281\n",
      "Batch : 340, Loss : 0.03842521458864212\n",
      "Batch : 350, Loss : 0.385196328163147\n",
      "Batch : 360, Loss : 0.16730743646621704\n",
      "Batch : 370, Loss : 0.04796202480792999\n",
      "Batch : 380, Loss : 0.014065305702388287\n",
      "Batch : 390, Loss : 0.0558784157037735\n",
      "Batch : 400, Loss : 0.0192981269210577\n",
      "Batch : 410, Loss : 0.14843299984931946\n",
      "Batch : 420, Loss : 0.18751098215579987\n",
      "Batch : 430, Loss : 0.06839045882225037\n",
      "Batch : 440, Loss : 0.004326305352151394\n",
      "Batch : 450, Loss : 0.1191052570939064\n",
      "Batch : 460, Loss : 0.1063915267586708\n",
      "Batch : 470, Loss : 0.16794387996196747\n",
      "Batch : 480, Loss : 0.11313874274492264\n",
      "Batch : 490, Loss : 0.10003861784934998\n",
      "Batch : 500, Loss : 0.0570797473192215\n",
      "Batch : 510, Loss : 0.017822997644543648\n",
      "Batch : 520, Loss : 0.23446495831012726\n",
      "Batch : 530, Loss : 0.06631924211978912\n",
      "Batch : 540, Loss : 0.10955978184938431\n",
      "Batch : 550, Loss : 0.06506031006574631\n",
      "Batch : 560, Loss : 0.018256425857543945\n",
      "Batch : 570, Loss : 0.04808131977915764\n",
      "Batch : 580, Loss : 0.1234966367483139\n",
      "Batch : 590, Loss : 0.13096211850643158\n",
      "Batch : 600, Loss : 0.004262434784322977\n",
      "Batch : 610, Loss : 0.02224341221153736\n",
      "Batch : 620, Loss : 0.346815824508667\n",
      "Batch : 630, Loss : 0.036211080849170685\n",
      "Batch : 640, Loss : 0.009380647912621498\n",
      "Batch : 650, Loss : 0.07535844296216965\n",
      "Batch : 660, Loss : 0.1775207221508026\n",
      "Batch : 670, Loss : 0.1233978420495987\n",
      "Batch : 680, Loss : 0.034267716109752655\n",
      "Batch : 690, Loss : 0.11075089126825333\n",
      "Batch : 700, Loss : 0.07534509897232056\n",
      "Batch : 710, Loss : 0.08461832255125046\n",
      "Batch : 720, Loss : 0.08803914487361908\n",
      "Batch : 730, Loss : 0.17295803129673004\n",
      "Batch : 740, Loss : 0.05759596452116966\n",
      "Batch : 750, Loss : 0.08533640205860138\n",
      "Batch : 760, Loss : 0.012856198474764824\n",
      "Batch : 770, Loss : 0.11110645532608032\n",
      "Batch : 780, Loss : 0.0020698148291558027\n",
      "Batch : 790, Loss : 0.021119223907589912\n",
      "Batch : 800, Loss : 0.180619016289711\n",
      "Batch : 810, Loss : 0.07450022548437119\n",
      "Batch : 820, Loss : 0.026963844895362854\n",
      "Batch : 830, Loss : 0.07988235354423523\n",
      "Batch : 840, Loss : 0.0009227751870639622\n",
      "Batch : 850, Loss : 0.11078568547964096\n",
      "Batch : 860, Loss : 0.005430947057902813\n",
      "Batch : 870, Loss : 0.31003251671791077\n",
      "Batch : 880, Loss : 0.045982323586940765\n",
      "Batch : 890, Loss : 0.18651461601257324\n",
      "Batch : 900, Loss : 0.019328953698277473\n",
      "Batch : 910, Loss : 0.15647761523723602\n",
      "Batch : 920, Loss : 0.06171514838933945\n",
      "Batch : 930, Loss : 0.006840011104941368\n",
      "Batch : 940, Loss : 0.010419297963380814\n",
      "Batch : 950, Loss : 0.06638631224632263\n",
      "Batch : 960, Loss : 0.22512280941009521\n",
      "Batch : 970, Loss : 0.009352268651127815\n",
      "Batch : 980, Loss : 0.18975050747394562\n",
      "Batch : 990, Loss : 0.0871642529964447\n",
      "Batch : 1000, Loss : 0.032992564141750336\n",
      "Batch : 1010, Loss : 0.1568838655948639\n",
      "Batch : 1020, Loss : 0.19922584295272827\n",
      "Batch : 1030, Loss : 0.020302768796682358\n",
      "Batch : 1040, Loss : 0.15341030061244965\n",
      "Batch : 1050, Loss : 0.08238804340362549\n",
      "Batch : 1060, Loss : 0.023250313475728035\n",
      "Batch : 1070, Loss : 0.007411678321659565\n",
      "Batch : 1080, Loss : 0.27619659900665283\n",
      "Batch : 1090, Loss : 0.017158981412649155\n",
      "Batch : 1100, Loss : 0.010952959768474102\n",
      "Batch : 1110, Loss : 0.07511478662490845\n",
      "Batch : 1120, Loss : 0.035408321768045425\n",
      "Batch : 1130, Loss : 0.10012640058994293\n",
      "Batch : 1140, Loss : 0.012667149305343628\n",
      "Batch : 1150, Loss : 0.005310914944857359\n",
      "Batch : 1160, Loss : 0.0047296094708144665\n",
      "Batch : 1170, Loss : 0.39480358362197876\n",
      "Batch : 1180, Loss : 0.01685229502618313\n",
      "Batch : 1190, Loss : 0.007976589724421501\n",
      "Batch : 1200, Loss : 0.09006504714488983\n",
      "Batch : 1210, Loss : 0.005082286428660154\n",
      "Batch : 1220, Loss : 0.003875113558024168\n",
      "Batch : 1230, Loss : 0.11391538381576538\n",
      "Batch : 1240, Loss : 0.010910360142588615\n",
      "Batch : 1250, Loss : 0.04048221558332443\n",
      "Batch : 1260, Loss : 0.0982116311788559\n",
      "Batch : 1270, Loss : 0.0026846351101994514\n",
      "Batch : 1280, Loss : 0.008071845397353172\n",
      "Batch : 1290, Loss : 0.012663673609495163\n",
      "Batch : 1300, Loss : 0.01883239857852459\n",
      "Batch : 1310, Loss : 0.245203897356987\n",
      "Batch : 1320, Loss : 0.11956782639026642\n",
      "Batch : 1330, Loss : 0.06872973591089249\n",
      "Batch : 1340, Loss : 0.009693541564047337\n",
      "Batch : 1350, Loss : 0.30005747079849243\n",
      "Batch : 1360, Loss : 0.11322423070669174\n",
      "Batch : 1370, Loss : 0.008671445772051811\n",
      "Batch : 1380, Loss : 0.21187669038772583\n",
      "Batch : 1390, Loss : 0.05264271795749664\n",
      "Batch : 1400, Loss : 0.04139585793018341\n",
      "Batch : 1410, Loss : 0.02278856188058853\n",
      "Batch : 1420, Loss : 0.012325811199843884\n",
      "Batch : 1430, Loss : 0.16509953141212463\n",
      "Batch : 1440, Loss : 0.04119657352566719\n",
      "Batch : 1450, Loss : 0.04890713095664978\n",
      "Batch : 1460, Loss : 0.011106261052191257\n",
      "Batch : 1470, Loss : 0.1491575688123703\n",
      "Batch : 1480, Loss : 0.08871482312679291\n",
      "Batch : 1490, Loss : 0.24677662551403046\n",
      "Batch : 1500, Loss : 0.00861486978828907\n",
      "Batch : 1510, Loss : 0.009090032428503036\n",
      "Batch : 1520, Loss : 0.2014695405960083\n",
      "Batch : 1530, Loss : 0.14108726382255554\n",
      "Batch : 1540, Loss : 0.030875302851200104\n",
      "Batch : 1550, Loss : 0.05242769047617912\n",
      "Batch : 1560, Loss : 0.0387069433927536\n",
      "Batch : 1570, Loss : 0.05461464822292328\n",
      "Batch : 1580, Loss : 0.036659758538007736\n",
      "Batch : 1590, Loss : 0.33736956119537354\n",
      "Batch : 1600, Loss : 0.028289956972002983\n",
      "Batch : 1610, Loss : 0.031679917126894\n",
      "Batch : 1620, Loss : 0.042741429060697556\n",
      "Batch : 1630, Loss : 0.07493320852518082\n",
      "Batch : 1640, Loss : 0.18435059487819672\n",
      "Batch : 1650, Loss : 0.058873727917671204\n",
      "Batch : 1660, Loss : 0.36729902029037476\n",
      "Batch : 1670, Loss : 0.01863359659910202\n",
      "Batch : 1680, Loss : 0.023276232182979584\n",
      "Batch : 1690, Loss : 0.16383156180381775\n",
      "Batch : 1700, Loss : 0.07709981501102448\n",
      "Batch : 1710, Loss : 0.07839083671569824\n",
      "Batch : 1720, Loss : 0.03731096535921097\n",
      "Batch : 1730, Loss : 0.5981705188751221\n",
      "Batch : 1740, Loss : 0.023288393393158913\n",
      "Batch : 1750, Loss : 0.058493174612522125\n",
      "Batch : 1760, Loss : 0.02346491999924183\n",
      "Batch : 1770, Loss : 0.15876035392284393\n",
      "Batch : 1780, Loss : 0.16630229353904724\n",
      "Batch : 1790, Loss : 0.227345809340477\n",
      "Batch : 1800, Loss : 0.012729143723845482\n",
      "Batch : 1810, Loss : 0.25856417417526245\n",
      "Batch : 1820, Loss : 0.06444688886404037\n",
      "Batch : 1830, Loss : 0.008095618337392807\n",
      "Batch : 1840, Loss : 0.05256578326225281\n",
      "Batch : 1850, Loss : 0.04363889619708061\n",
      "Batch : 1860, Loss : 0.018315285444259644\n",
      "Batch : 1870, Loss : 0.04966700077056885\n",
      "Epoch : 1\n",
      "Batch : 0, Loss : 0.057374805212020874\n",
      "Batch : 10, Loss : 0.1564035564661026\n",
      "Batch : 20, Loss : 0.09528147429227829\n",
      "Batch : 30, Loss : 0.021914634853601456\n",
      "Batch : 40, Loss : 0.11364150792360306\n",
      "Batch : 50, Loss : 0.012295841239392757\n",
      "Batch : 60, Loss : 0.023535719141364098\n",
      "Batch : 70, Loss : 0.012474538758397102\n",
      "Batch : 80, Loss : 0.0010688137263059616\n",
      "Batch : 90, Loss : 0.024862447753548622\n",
      "Batch : 100, Loss : 0.029458921402692795\n",
      "Batch : 110, Loss : 0.09372486174106598\n",
      "Batch : 120, Loss : 0.04673308506608009\n",
      "Batch : 130, Loss : 0.016012726351618767\n",
      "Batch : 140, Loss : 0.020493533462285995\n",
      "Batch : 150, Loss : 0.025594238191843033\n",
      "Batch : 160, Loss : 0.00823955051600933\n",
      "Batch : 170, Loss : 0.0261809304356575\n",
      "Batch : 180, Loss : 0.01764472760260105\n",
      "Batch : 190, Loss : 0.002299610525369644\n",
      "Batch : 200, Loss : 0.058307092636823654\n",
      "Batch : 210, Loss : 0.06900645792484283\n",
      "Batch : 220, Loss : 0.06262745708227158\n",
      "Batch : 230, Loss : 0.017020367085933685\n",
      "Batch : 240, Loss : 0.030828706920146942\n",
      "Batch : 250, Loss : 0.003302966943010688\n",
      "Batch : 260, Loss : 0.1574336737394333\n",
      "Batch : 270, Loss : 0.045243021100759506\n",
      "Batch : 280, Loss : 0.02620004117488861\n",
      "Batch : 290, Loss : 0.011983712203800678\n",
      "Batch : 300, Loss : 0.03374066576361656\n",
      "Batch : 310, Loss : 0.11523553729057312\n",
      "Batch : 320, Loss : 0.15588247776031494\n",
      "Batch : 330, Loss : 0.04329317808151245\n",
      "Batch : 340, Loss : 0.0365251749753952\n",
      "Batch : 350, Loss : 0.030771732330322266\n",
      "Batch : 360, Loss : 0.00851723924279213\n",
      "Batch : 370, Loss : 0.04969486594200134\n",
      "Batch : 380, Loss : 0.0018396234372630715\n",
      "Batch : 390, Loss : 0.10312053561210632\n",
      "Batch : 400, Loss : 0.05674034729599953\n",
      "Batch : 410, Loss : 0.09226870536804199\n",
      "Batch : 420, Loss : 0.055920667946338654\n",
      "Batch : 430, Loss : 0.06885445863008499\n",
      "Batch : 440, Loss : 0.020578065887093544\n",
      "Batch : 450, Loss : 0.013078108429908752\n",
      "Batch : 460, Loss : 0.006531926803290844\n",
      "Batch : 470, Loss : 0.05072849988937378\n",
      "Batch : 480, Loss : 0.011143466457724571\n",
      "Batch : 490, Loss : 0.0038185003213584423\n",
      "Batch : 500, Loss : 0.029228869825601578\n",
      "Batch : 510, Loss : 0.05033312737941742\n",
      "Batch : 520, Loss : 0.15284495055675507\n",
      "Batch : 530, Loss : 0.03386718034744263\n",
      "Batch : 540, Loss : 0.1212836280465126\n",
      "Batch : 550, Loss : 0.011446944437921047\n",
      "Batch : 560, Loss : 0.28534287214279175\n",
      "Batch : 570, Loss : 0.06563256680965424\n",
      "Batch : 580, Loss : 0.06639662384986877\n",
      "Batch : 590, Loss : 0.044322602450847626\n",
      "Batch : 600, Loss : 0.21223172545433044\n",
      "Batch : 610, Loss : 0.008272841572761536\n",
      "Batch : 620, Loss : 0.048935312777757645\n",
      "Batch : 630, Loss : 0.1313817948102951\n",
      "Batch : 640, Loss : 0.2664816081523895\n",
      "Batch : 650, Loss : 0.02514023706316948\n",
      "Batch : 660, Loss : 0.0034502139315009117\n",
      "Batch : 670, Loss : 0.016352426260709763\n",
      "Batch : 680, Loss : 0.0026367229875177145\n",
      "Batch : 690, Loss : 0.014030500315129757\n",
      "Batch : 700, Loss : 0.2354193478822708\n",
      "Batch : 710, Loss : 0.00615935493260622\n",
      "Batch : 720, Loss : 0.2280118763446808\n",
      "Batch : 730, Loss : 0.010684695094823837\n",
      "Batch : 740, Loss : 0.08839724212884903\n",
      "Batch : 750, Loss : 0.04217963665723801\n",
      "Batch : 760, Loss : 0.0072703249752521515\n",
      "Batch : 770, Loss : 0.0312671922147274\n",
      "Batch : 780, Loss : 0.038529083132743835\n",
      "Batch : 790, Loss : 0.01852858066558838\n",
      "Batch : 800, Loss : 0.0509524941444397\n",
      "Batch : 810, Loss : 0.020817391574382782\n",
      "Batch : 820, Loss : 0.004710194189101458\n",
      "Batch : 830, Loss : 0.010977368801832199\n",
      "Batch : 840, Loss : 0.009889633394777775\n",
      "Batch : 850, Loss : 0.08784649521112442\n",
      "Batch : 860, Loss : 0.10579308122396469\n",
      "Batch : 870, Loss : 0.017467573285102844\n",
      "Batch : 880, Loss : 0.014911459758877754\n",
      "Batch : 890, Loss : 0.04651447758078575\n",
      "Batch : 900, Loss : 0.030780663713812828\n",
      "Batch : 910, Loss : 0.11159680038690567\n",
      "Batch : 920, Loss : 0.04778977483510971\n",
      "Batch : 930, Loss : 0.0040182373486459255\n",
      "Batch : 940, Loss : 0.11294682323932648\n",
      "Batch : 950, Loss : 0.1685163825750351\n",
      "Batch : 960, Loss : 0.15978406369686127\n",
      "Batch : 970, Loss : 0.03957061097025871\n",
      "Batch : 980, Loss : 0.045122019946575165\n",
      "Batch : 990, Loss : 0.19007118046283722\n",
      "Batch : 1000, Loss : 0.0030822886619716883\n",
      "Batch : 1010, Loss : 0.3716658055782318\n",
      "Batch : 1020, Loss : 0.06839320063591003\n",
      "Batch : 1030, Loss : 0.20243382453918457\n",
      "Batch : 1040, Loss : 0.13074089586734772\n",
      "Batch : 1050, Loss : 0.0014453610638156533\n",
      "Batch : 1060, Loss : 0.0038599707186222076\n",
      "Batch : 1070, Loss : 0.09267528355121613\n",
      "Batch : 1080, Loss : 0.2187286913394928\n",
      "Batch : 1090, Loss : 0.006568470504134893\n",
      "Batch : 1100, Loss : 0.0038922291714698076\n",
      "Batch : 1110, Loss : 0.04945622757077217\n",
      "Batch : 1120, Loss : 0.008725512772798538\n",
      "Batch : 1130, Loss : 0.1894354373216629\n",
      "Batch : 1140, Loss : 0.001880938420072198\n",
      "Batch : 1150, Loss : 0.16177214682102203\n",
      "Batch : 1160, Loss : 0.0883181020617485\n",
      "Batch : 1170, Loss : 0.011693563312292099\n",
      "Batch : 1180, Loss : 0.32227835059165955\n",
      "Batch : 1190, Loss : 0.0065422262996435165\n",
      "Batch : 1200, Loss : 0.10387377440929413\n",
      "Batch : 1210, Loss : 0.0744798481464386\n",
      "Batch : 1220, Loss : 0.44223931431770325\n",
      "Batch : 1230, Loss : 0.07579144090414047\n",
      "Batch : 1240, Loss : 0.17296826839447021\n",
      "Batch : 1250, Loss : 0.002927506808191538\n",
      "Batch : 1260, Loss : 0.25763052701950073\n",
      "Batch : 1270, Loss : 0.041206974536180496\n",
      "Batch : 1280, Loss : 0.035787470638751984\n",
      "Batch : 1290, Loss : 0.09102658182382584\n",
      "Batch : 1300, Loss : 0.00820477120578289\n",
      "Batch : 1310, Loss : 0.02205897867679596\n",
      "Batch : 1320, Loss : 0.045681096613407135\n",
      "Batch : 1330, Loss : 0.003652337472885847\n",
      "Batch : 1340, Loss : 0.021189827471971512\n",
      "Batch : 1350, Loss : 0.03797020763158798\n",
      "Batch : 1360, Loss : 0.12878793478012085\n",
      "Batch : 1370, Loss : 0.03716433793306351\n",
      "Batch : 1380, Loss : 0.04275102913379669\n",
      "Batch : 1390, Loss : 0.022944321855902672\n",
      "Batch : 1400, Loss : 0.04875558614730835\n",
      "Batch : 1410, Loss : 0.026979677379131317\n",
      "Batch : 1420, Loss : 0.001068013720214367\n",
      "Batch : 1430, Loss : 0.0312836728990078\n",
      "Batch : 1440, Loss : 0.0058346763253211975\n",
      "Batch : 1450, Loss : 0.0013249748153612018\n",
      "Batch : 1460, Loss : 0.009813809767365456\n",
      "Batch : 1470, Loss : 0.04366671293973923\n",
      "Batch : 1480, Loss : 0.0047869374975562096\n",
      "Batch : 1490, Loss : 0.27247515320777893\n",
      "Batch : 1500, Loss : 0.022282032296061516\n",
      "Batch : 1510, Loss : 0.1153087168931961\n",
      "Batch : 1520, Loss : 0.0027548340149223804\n",
      "Batch : 1530, Loss : 0.05476967990398407\n",
      "Batch : 1540, Loss : 0.09154854714870453\n",
      "Batch : 1550, Loss : 0.024568207561969757\n",
      "Batch : 1560, Loss : 0.08312106877565384\n",
      "Batch : 1570, Loss : 0.4546390175819397\n",
      "Batch : 1580, Loss : 0.1100383773446083\n",
      "Batch : 1590, Loss : 0.02340640500187874\n",
      "Batch : 1600, Loss : 0.1002369225025177\n",
      "Batch : 1610, Loss : 0.04922637343406677\n",
      "Batch : 1620, Loss : 0.017147094011306763\n",
      "Batch : 1630, Loss : 0.007549942005425692\n",
      "Batch : 1640, Loss : 0.04030118137598038\n",
      "Batch : 1650, Loss : 0.15596741437911987\n",
      "Batch : 1660, Loss : 0.10264439135789871\n",
      "Batch : 1670, Loss : 0.10616859048604965\n",
      "Batch : 1680, Loss : 0.026904134079813957\n",
      "Batch : 1690, Loss : 0.023619793355464935\n",
      "Batch : 1700, Loss : 0.02152438461780548\n",
      "Batch : 1710, Loss : 0.013449371792376041\n",
      "Batch : 1720, Loss : 0.21114563941955566\n",
      "Batch : 1730, Loss : 0.0312952846288681\n",
      "Batch : 1740, Loss : 0.03369459882378578\n",
      "Batch : 1750, Loss : 0.028669938445091248\n",
      "Batch : 1760, Loss : 0.019928330555558205\n",
      "Batch : 1770, Loss : 0.10607356578111649\n",
      "Batch : 1780, Loss : 0.02202165126800537\n",
      "Batch : 1790, Loss : 0.0031722355633974075\n",
      "Batch : 1800, Loss : 0.1825781911611557\n",
      "Batch : 1810, Loss : 0.0293266661465168\n",
      "Batch : 1820, Loss : 0.0018244956154376268\n",
      "Batch : 1830, Loss : 0.1420496702194214\n",
      "Batch : 1840, Loss : 0.16598916053771973\n",
      "Batch : 1850, Loss : 0.08565114438533783\n",
      "Batch : 1860, Loss : 0.030668286606669426\n",
      "Batch : 1870, Loss : 0.34576019644737244\n",
      "Epoch : 2\n",
      "Batch : 0, Loss : 0.013553213328123093\n",
      "Batch : 10, Loss : 0.013848135247826576\n",
      "Batch : 20, Loss : 0.004670170601457357\n",
      "Batch : 30, Loss : 0.004315623082220554\n",
      "Batch : 40, Loss : 0.013398827984929085\n",
      "Batch : 50, Loss : 0.03370027616620064\n",
      "Batch : 60, Loss : 0.01710423082113266\n",
      "Batch : 70, Loss : 0.054088544100522995\n",
      "Batch : 80, Loss : 0.004014293663203716\n",
      "Batch : 90, Loss : 0.0501122921705246\n",
      "Batch : 100, Loss : 0.006062604952603579\n",
      "Batch : 110, Loss : 0.008144629187881947\n",
      "Batch : 120, Loss : 0.00757214380428195\n",
      "Batch : 130, Loss : 0.016932280734181404\n",
      "Batch : 140, Loss : 0.004136214964091778\n",
      "Batch : 150, Loss : 0.03931526839733124\n",
      "Batch : 160, Loss : 0.03193480148911476\n",
      "Batch : 170, Loss : 0.009511961601674557\n",
      "Batch : 180, Loss : 0.13718606531620026\n",
      "Batch : 190, Loss : 0.0017007316928356886\n",
      "Batch : 200, Loss : 0.044140253216028214\n",
      "Batch : 210, Loss : 0.011023983359336853\n",
      "Batch : 220, Loss : 0.03712145611643791\n",
      "Batch : 230, Loss : 0.31248632073402405\n",
      "Batch : 240, Loss : 0.08286811411380768\n",
      "Batch : 250, Loss : 0.003151319222524762\n",
      "Batch : 260, Loss : 0.015049774199724197\n",
      "Batch : 270, Loss : 0.06146024167537689\n",
      "Batch : 280, Loss : 0.0005301668425090611\n",
      "Batch : 290, Loss : 0.0071291737258434296\n",
      "Batch : 300, Loss : 0.004542231559753418\n",
      "Batch : 310, Loss : 0.01528337225317955\n",
      "Batch : 320, Loss : 0.00406966358423233\n",
      "Batch : 330, Loss : 0.028032269328832626\n",
      "Batch : 340, Loss : 0.008226548321545124\n",
      "Batch : 350, Loss : 0.0239681676030159\n",
      "Batch : 360, Loss : 0.0024854557123035192\n",
      "Batch : 370, Loss : 0.0006561234476976097\n",
      "Batch : 380, Loss : 0.13022860884666443\n",
      "Batch : 390, Loss : 0.0490310899913311\n",
      "Batch : 400, Loss : 0.009059763513505459\n",
      "Batch : 410, Loss : 0.012294650077819824\n",
      "Batch : 420, Loss : 0.0055236113257706165\n",
      "Batch : 430, Loss : 0.036804281175136566\n",
      "Batch : 440, Loss : 0.03281169384717941\n",
      "Batch : 450, Loss : 0.01765049248933792\n",
      "Batch : 460, Loss : 0.11082678288221359\n",
      "Batch : 470, Loss : 0.019926678389310837\n",
      "Batch : 480, Loss : 0.0009812237694859505\n",
      "Batch : 490, Loss : 0.016061164438724518\n",
      "Batch : 500, Loss : 0.0086279371753335\n",
      "Batch : 510, Loss : 0.08831318467855453\n",
      "Batch : 520, Loss : 0.0016700385604053736\n",
      "Batch : 530, Loss : 0.06071597710251808\n",
      "Batch : 540, Loss : 0.01403189916163683\n",
      "Batch : 550, Loss : 0.004127352498471737\n",
      "Batch : 560, Loss : 0.004043901804834604\n",
      "Batch : 570, Loss : 0.0023533962666988373\n",
      "Batch : 580, Loss : 0.06899368762969971\n",
      "Batch : 590, Loss : 0.01286031398922205\n",
      "Batch : 600, Loss : 0.009814100340008736\n",
      "Batch : 610, Loss : 0.004211815074086189\n",
      "Batch : 620, Loss : 0.007141969632357359\n",
      "Batch : 630, Loss : 0.0025249698664993048\n",
      "Batch : 640, Loss : 0.0727761760354042\n",
      "Batch : 650, Loss : 0.002713496098294854\n",
      "Batch : 660, Loss : 0.00048404510016553104\n",
      "Batch : 670, Loss : 0.05318398401141167\n",
      "Batch : 680, Loss : 0.006749588064849377\n",
      "Batch : 690, Loss : 0.03776885196566582\n",
      "Batch : 700, Loss : 0.009011425077915192\n",
      "Batch : 710, Loss : 0.01969064772129059\n",
      "Batch : 720, Loss : 0.09877541661262512\n",
      "Batch : 730, Loss : 0.00048803974641487\n",
      "Batch : 740, Loss : 0.028590871021151543\n",
      "Batch : 750, Loss : 0.085936538875103\n",
      "Batch : 760, Loss : 0.0002772951265797019\n",
      "Batch : 770, Loss : 0.055408578366041183\n",
      "Batch : 780, Loss : 0.07661046832799911\n",
      "Batch : 790, Loss : 0.11133093386888504\n",
      "Batch : 800, Loss : 0.016930734738707542\n",
      "Batch : 810, Loss : 0.03503645211458206\n",
      "Batch : 820, Loss : 0.021183164790272713\n",
      "Batch : 830, Loss : 0.027248231694102287\n",
      "Batch : 840, Loss : 0.05588172748684883\n",
      "Batch : 850, Loss : 0.07078992575407028\n",
      "Batch : 860, Loss : 0.2714836001396179\n",
      "Batch : 870, Loss : 0.029895693063735962\n",
      "Batch : 880, Loss : 0.029165999963879585\n",
      "Batch : 890, Loss : 0.10780398547649384\n",
      "Batch : 900, Loss : 0.05923183634877205\n",
      "Batch : 910, Loss : 0.10573797672986984\n",
      "Batch : 920, Loss : 0.007182661909610033\n",
      "Batch : 930, Loss : 0.09278032183647156\n",
      "Batch : 940, Loss : 0.005666558630764484\n",
      "Batch : 950, Loss : 0.0043685850687325\n",
      "Batch : 960, Loss : 0.002490611979737878\n",
      "Batch : 970, Loss : 0.03790570795536041\n",
      "Batch : 980, Loss : 0.0624878816306591\n",
      "Batch : 990, Loss : 0.02735726349055767\n",
      "Batch : 1000, Loss : 0.0028933940920978785\n",
      "Batch : 1010, Loss : 0.3222002685070038\n",
      "Batch : 1020, Loss : 0.0007084765238687396\n",
      "Batch : 1030, Loss : 0.0045824842527508736\n",
      "Batch : 1040, Loss : 0.02865702100098133\n",
      "Batch : 1050, Loss : 0.00123870768584311\n",
      "Batch : 1060, Loss : 0.05809161812067032\n",
      "Batch : 1070, Loss : 0.0011105361627414823\n",
      "Batch : 1080, Loss : 0.004887619521468878\n",
      "Batch : 1090, Loss : 0.02322646975517273\n",
      "Batch : 1100, Loss : 0.15164192020893097\n",
      "Batch : 1110, Loss : 0.018150579184293747\n",
      "Batch : 1120, Loss : 0.004535735584795475\n",
      "Batch : 1130, Loss : 0.009481510147452354\n",
      "Batch : 1140, Loss : 0.004361355677247047\n",
      "Batch : 1150, Loss : 0.03397534042596817\n",
      "Batch : 1160, Loss : 0.02828012965619564\n",
      "Batch : 1170, Loss : 0.005830261390656233\n",
      "Batch : 1180, Loss : 0.012947971001267433\n",
      "Batch : 1190, Loss : 0.004719560965895653\n",
      "Batch : 1200, Loss : 0.013125445693731308\n",
      "Batch : 1210, Loss : 0.0017979334807023406\n",
      "Batch : 1220, Loss : 0.008690382353961468\n",
      "Batch : 1230, Loss : 0.27784058451652527\n",
      "Batch : 1240, Loss : 0.05843799561262131\n",
      "Batch : 1250, Loss : 0.005265862215310335\n",
      "Batch : 1260, Loss : 0.1749778836965561\n",
      "Batch : 1270, Loss : 0.04519324377179146\n",
      "Batch : 1280, Loss : 0.09103932231664658\n",
      "Batch : 1290, Loss : 0.048197753727436066\n",
      "Batch : 1300, Loss : 0.04227695241570473\n",
      "Batch : 1310, Loss : 0.011214831843972206\n",
      "Batch : 1320, Loss : 0.003938859328627586\n",
      "Batch : 1330, Loss : 0.0006640544161200523\n",
      "Batch : 1340, Loss : 0.0012899679131805897\n",
      "Batch : 1350, Loss : 0.0015266190748661757\n",
      "Batch : 1360, Loss : 0.0007535539916716516\n",
      "Batch : 1370, Loss : 0.054107747972011566\n",
      "Batch : 1380, Loss : 0.06192619726061821\n",
      "Batch : 1390, Loss : 0.00804980006068945\n",
      "Batch : 1400, Loss : 0.07386963814496994\n",
      "Batch : 1410, Loss : 0.00746471993625164\n",
      "Batch : 1420, Loss : 0.046078041195869446\n",
      "Batch : 1430, Loss : 0.004737665876746178\n",
      "Batch : 1440, Loss : 0.06239640712738037\n",
      "Batch : 1450, Loss : 0.0014323435025289655\n",
      "Batch : 1460, Loss : 0.03230904042720795\n",
      "Batch : 1470, Loss : 0.037266235798597336\n",
      "Batch : 1480, Loss : 0.001740200794301927\n",
      "Batch : 1490, Loss : 0.04332679882645607\n",
      "Batch : 1500, Loss : 0.003677805420011282\n",
      "Batch : 1510, Loss : 0.0012897008564323187\n",
      "Batch : 1520, Loss : 0.025864439085125923\n",
      "Batch : 1530, Loss : 0.0038871299475431442\n",
      "Batch : 1540, Loss : 0.06109904125332832\n",
      "Batch : 1550, Loss : 0.006440220400691032\n",
      "Batch : 1560, Loss : 0.008194906637072563\n",
      "Batch : 1570, Loss : 0.0041910698637366295\n",
      "Batch : 1580, Loss : 0.05137812718749046\n",
      "Batch : 1590, Loss : 0.0002820659428834915\n",
      "Batch : 1600, Loss : 0.10922594368457794\n",
      "Batch : 1610, Loss : 0.04487285017967224\n",
      "Batch : 1620, Loss : 0.04505772143602371\n",
      "Batch : 1630, Loss : 0.00014219613512977958\n",
      "Batch : 1640, Loss : 0.0024774386547505856\n",
      "Batch : 1650, Loss : 0.06936231255531311\n",
      "Batch : 1660, Loss : 0.004676903132349253\n",
      "Batch : 1670, Loss : 0.20127765834331512\n",
      "Batch : 1680, Loss : 0.1824951320886612\n",
      "Batch : 1690, Loss : 0.0073152449913322926\n",
      "Batch : 1700, Loss : 0.0006320279790088534\n",
      "Batch : 1710, Loss : 0.0014076598454266787\n",
      "Batch : 1720, Loss : 0.00908184889703989\n",
      "Batch : 1730, Loss : 0.011973894201219082\n",
      "Batch : 1740, Loss : 0.03068121150135994\n",
      "Batch : 1750, Loss : 0.05134234204888344\n",
      "Batch : 1760, Loss : 0.06468582153320312\n",
      "Batch : 1770, Loss : 0.0019691642373800278\n",
      "Batch : 1780, Loss : 0.012991667725145817\n",
      "Batch : 1790, Loss : 0.0013216538354754448\n",
      "Batch : 1800, Loss : 0.01929127424955368\n",
      "Batch : 1810, Loss : 0.16035762429237366\n",
      "Batch : 1820, Loss : 0.012267345562577248\n",
      "Batch : 1830, Loss : 0.01496900711208582\n",
      "Batch : 1840, Loss : 0.05281321704387665\n",
      "Batch : 1850, Loss : 0.19682426750659943\n",
      "Batch : 1860, Loss : 0.11831164360046387\n",
      "Batch : 1870, Loss : 0.0027305567637085915\n",
      "Epoch : 3\n",
      "Batch : 0, Loss : 0.001701354281976819\n",
      "Batch : 10, Loss : 0.006233080755919218\n",
      "Batch : 20, Loss : 0.02669679746031761\n",
      "Batch : 30, Loss : 0.05884157493710518\n",
      "Batch : 40, Loss : 0.0021399392280727625\n",
      "Batch : 50, Loss : 0.06801875680685043\n",
      "Batch : 60, Loss : 0.11687692254781723\n",
      "Batch : 70, Loss : 0.007396758068352938\n",
      "Batch : 80, Loss : 0.023099195212125778\n",
      "Batch : 90, Loss : 0.14041753113269806\n",
      "Batch : 100, Loss : 0.006459207274019718\n",
      "Batch : 110, Loss : 0.10650037974119186\n",
      "Batch : 120, Loss : 0.1768265962600708\n",
      "Batch : 130, Loss : 0.006725614424794912\n",
      "Batch : 140, Loss : 0.05622602254152298\n",
      "Batch : 150, Loss : 0.022366782650351524\n",
      "Batch : 160, Loss : 0.003016631118953228\n",
      "Batch : 170, Loss : 0.19362184405326843\n",
      "Batch : 180, Loss : 0.01897123083472252\n",
      "Batch : 190, Loss : 0.008151762187480927\n",
      "Batch : 200, Loss : 0.04158444330096245\n",
      "Batch : 210, Loss : 0.0014465887797996402\n",
      "Batch : 220, Loss : 0.00111336016561836\n",
      "Batch : 230, Loss : 0.0014255763962864876\n",
      "Batch : 240, Loss : 0.002510599559172988\n",
      "Batch : 250, Loss : 0.018844543024897575\n",
      "Batch : 260, Loss : 0.042916327714920044\n",
      "Batch : 270, Loss : 0.03038875386118889\n",
      "Batch : 280, Loss : 0.00231312052346766\n",
      "Batch : 290, Loss : 0.0014561567222699523\n",
      "Batch : 300, Loss : 0.01525483001023531\n",
      "Batch : 310, Loss : 0.006518997251987457\n",
      "Batch : 320, Loss : 0.007500200532376766\n",
      "Batch : 330, Loss : 0.004072495736181736\n",
      "Batch : 340, Loss : 0.005583451595157385\n",
      "Batch : 350, Loss : 0.10195232182741165\n",
      "Batch : 360, Loss : 0.0018959505250677466\n",
      "Batch : 370, Loss : 0.0013796064304187894\n",
      "Batch : 380, Loss : 0.0016628524754196405\n",
      "Batch : 390, Loss : 0.002726568840444088\n",
      "Batch : 400, Loss : 0.020860109478235245\n",
      "Batch : 410, Loss : 0.0017719834577292204\n",
      "Batch : 420, Loss : 0.003510399255901575\n",
      "Batch : 430, Loss : 0.09663823246955872\n",
      "Batch : 440, Loss : 0.004032053519040346\n",
      "Batch : 450, Loss : 0.0017609363421797752\n",
      "Batch : 460, Loss : 0.005136513616889715\n",
      "Batch : 470, Loss : 0.014961211010813713\n",
      "Batch : 480, Loss : 0.001109978067688644\n",
      "Batch : 490, Loss : 0.07993054389953613\n",
      "Batch : 500, Loss : 0.006214963272213936\n",
      "Batch : 510, Loss : 0.003876015078276396\n",
      "Batch : 520, Loss : 0.06167416274547577\n",
      "Batch : 530, Loss : 0.001430177828297019\n",
      "Batch : 540, Loss : 0.010608924552798271\n",
      "Batch : 550, Loss : 0.05727362260222435\n",
      "Batch : 560, Loss : 0.008206532336771488\n",
      "Batch : 570, Loss : 0.005307689309120178\n",
      "Batch : 580, Loss : 0.0037585829850286245\n",
      "Batch : 590, Loss : 0.04793412610888481\n",
      "Batch : 600, Loss : 0.00018780016398523003\n",
      "Batch : 610, Loss : 0.002005527028813958\n",
      "Batch : 620, Loss : 0.00010903175279963762\n",
      "Batch : 630, Loss : 0.30004939436912537\n",
      "Batch : 640, Loss : 0.11653938889503479\n",
      "Batch : 650, Loss : 0.040373027324676514\n",
      "Batch : 660, Loss : 0.0002851580793503672\n",
      "Batch : 670, Loss : 0.005185483954846859\n",
      "Batch : 680, Loss : 0.03193182125687599\n",
      "Batch : 690, Loss : 0.06459054350852966\n",
      "Batch : 700, Loss : 0.001842247904278338\n",
      "Batch : 710, Loss : 0.003400225890800357\n",
      "Batch : 720, Loss : 0.0026986238081008196\n",
      "Batch : 730, Loss : 0.09173377603292465\n",
      "Batch : 740, Loss : 0.002023295732215047\n",
      "Batch : 750, Loss : 0.20712077617645264\n",
      "Batch : 760, Loss : 0.003130659693852067\n",
      "Batch : 770, Loss : 0.0008178002899512649\n",
      "Batch : 780, Loss : 0.0855560377240181\n",
      "Batch : 790, Loss : 0.04978715255856514\n",
      "Batch : 800, Loss : 0.010332569479942322\n",
      "Batch : 810, Loss : 0.010354021564126015\n",
      "Batch : 820, Loss : 0.0002672236878424883\n",
      "Batch : 830, Loss : 0.03040718473494053\n",
      "Batch : 840, Loss : 0.013829813338816166\n",
      "Batch : 850, Loss : 0.06918372958898544\n",
      "Batch : 860, Loss : 0.04789501056075096\n",
      "Batch : 870, Loss : 0.07446134835481644\n",
      "Batch : 880, Loss : 0.009429516270756721\n",
      "Batch : 890, Loss : 0.006140123121440411\n",
      "Batch : 900, Loss : 0.009183352813124657\n",
      "Batch : 910, Loss : 0.07347901910543442\n",
      "Batch : 920, Loss : 0.06223205476999283\n",
      "Batch : 930, Loss : 0.012222230434417725\n",
      "Batch : 940, Loss : 0.07057265937328339\n",
      "Batch : 950, Loss : 0.04112708196043968\n",
      "Batch : 960, Loss : 0.0033541517332196236\n",
      "Batch : 970, Loss : 0.01955801621079445\n",
      "Batch : 980, Loss : 0.08896320313215256\n",
      "Batch : 990, Loss : 0.011357755400240421\n",
      "Batch : 1000, Loss : 0.013009589165449142\n",
      "Batch : 1010, Loss : 0.019123325124382973\n",
      "Batch : 1020, Loss : 0.1650017946958542\n",
      "Batch : 1030, Loss : 0.00781558733433485\n",
      "Batch : 1040, Loss : 0.084491066634655\n",
      "Batch : 1050, Loss : 8.260004688054323e-05\n",
      "Batch : 1060, Loss : 0.047466080635786057\n",
      "Batch : 1070, Loss : 0.01014491356909275\n",
      "Batch : 1080, Loss : 0.02231053076684475\n",
      "Batch : 1090, Loss : 0.014444117434322834\n",
      "Batch : 1100, Loss : 0.0020561821293085814\n",
      "Batch : 1110, Loss : 0.14746063947677612\n",
      "Batch : 1120, Loss : 0.013965683057904243\n",
      "Batch : 1130, Loss : 0.02255833148956299\n",
      "Batch : 1140, Loss : 0.00225285766646266\n",
      "Batch : 1150, Loss : 0.0036952709779143333\n",
      "Batch : 1160, Loss : 0.016401777043938637\n",
      "Batch : 1170, Loss : 0.04555628448724747\n",
      "Batch : 1180, Loss : 0.0004572461184579879\n",
      "Batch : 1190, Loss : 0.0359686054289341\n",
      "Batch : 1200, Loss : 0.01851162500679493\n",
      "Batch : 1210, Loss : 0.0026491933967918158\n",
      "Batch : 1220, Loss : 0.023001529276371002\n",
      "Batch : 1230, Loss : 0.022943150252103806\n",
      "Batch : 1240, Loss : 0.0834295004606247\n",
      "Batch : 1250, Loss : 0.026657691225409508\n",
      "Batch : 1260, Loss : 0.1565655767917633\n",
      "Batch : 1270, Loss : 0.06040666252374649\n",
      "Batch : 1280, Loss : 0.014325438998639584\n",
      "Batch : 1290, Loss : 0.0006537156295962632\n",
      "Batch : 1300, Loss : 0.030754350125789642\n",
      "Batch : 1310, Loss : 0.005016426555812359\n",
      "Batch : 1320, Loss : 0.02851066365838051\n",
      "Batch : 1330, Loss : 0.02054605819284916\n",
      "Batch : 1340, Loss : 0.0006278607179410756\n",
      "Batch : 1350, Loss : 0.00885307788848877\n",
      "Batch : 1360, Loss : 0.0203566811978817\n",
      "Batch : 1370, Loss : 0.1526697427034378\n",
      "Batch : 1380, Loss : 0.04893295839428902\n",
      "Batch : 1390, Loss : 0.13711513578891754\n",
      "Batch : 1400, Loss : 0.02384316548705101\n",
      "Batch : 1410, Loss : 0.00040483364136889577\n",
      "Batch : 1420, Loss : 0.14528194069862366\n",
      "Batch : 1430, Loss : 0.004192451015114784\n",
      "Batch : 1440, Loss : 0.012262530624866486\n",
      "Batch : 1450, Loss : 0.0325622484087944\n",
      "Batch : 1460, Loss : 0.1311449408531189\n",
      "Batch : 1470, Loss : 0.007833928801119328\n",
      "Batch : 1480, Loss : 0.008375411853194237\n",
      "Batch : 1490, Loss : 0.020403262227773666\n",
      "Batch : 1500, Loss : 0.00038497106288559735\n",
      "Batch : 1510, Loss : 0.057403478771448135\n",
      "Batch : 1520, Loss : 0.1023576557636261\n",
      "Batch : 1530, Loss : 0.2127702385187149\n",
      "Batch : 1540, Loss : 0.029143687337636948\n",
      "Batch : 1550, Loss : 0.11143822968006134\n",
      "Batch : 1560, Loss : 0.002713154535740614\n",
      "Batch : 1570, Loss : 0.057907700538635254\n",
      "Batch : 1580, Loss : 0.0014067734591662884\n",
      "Batch : 1590, Loss : 0.008290660567581654\n",
      "Batch : 1600, Loss : 0.007947529666125774\n",
      "Batch : 1610, Loss : 0.00939061027020216\n",
      "Batch : 1620, Loss : 0.014759083278477192\n",
      "Batch : 1630, Loss : 0.006325026974081993\n",
      "Batch : 1640, Loss : 0.20565001666545868\n",
      "Batch : 1650, Loss : 0.06022251769900322\n",
      "Batch : 1660, Loss : 0.006272828672081232\n",
      "Batch : 1670, Loss : 0.0011894681956619024\n",
      "Batch : 1680, Loss : 0.00177050253842026\n",
      "Batch : 1690, Loss : 0.004068624693900347\n",
      "Batch : 1700, Loss : 0.004788377322256565\n",
      "Batch : 1710, Loss : 0.07231340557336807\n",
      "Batch : 1720, Loss : 0.028967123478651047\n",
      "Batch : 1730, Loss : 0.029797056689858437\n",
      "Batch : 1740, Loss : 0.034086719155311584\n",
      "Batch : 1750, Loss : 0.014884361065924168\n",
      "Batch : 1760, Loss : 0.015325222164392471\n",
      "Batch : 1770, Loss : 0.030777761712670326\n",
      "Batch : 1780, Loss : 0.006896524224430323\n",
      "Batch : 1790, Loss : 0.0007081749499775469\n",
      "Batch : 1800, Loss : 0.01720965839922428\n",
      "Batch : 1810, Loss : 0.005384956486523151\n",
      "Batch : 1820, Loss : 0.04656581953167915\n",
      "Batch : 1830, Loss : 0.07167769223451614\n",
      "Batch : 1840, Loss : 0.00845365785062313\n",
      "Batch : 1850, Loss : 0.0018431695643812418\n",
      "Batch : 1860, Loss : 0.0028313861694186926\n",
      "Batch : 1870, Loss : 0.02009786292910576\n",
      "Epoch : 4\n",
      "Batch : 0, Loss : 0.0032927650026977062\n",
      "Batch : 10, Loss : 0.015956655144691467\n",
      "Batch : 20, Loss : 0.01010183710604906\n",
      "Batch : 30, Loss : 0.0005200047744438052\n",
      "Batch : 40, Loss : 0.003895688569173217\n",
      "Batch : 50, Loss : 0.0024512524250894785\n",
      "Batch : 60, Loss : 0.0014544699806720018\n",
      "Batch : 70, Loss : 0.009274275973439217\n",
      "Batch : 80, Loss : 0.0053267041221261024\n",
      "Batch : 90, Loss : 0.0017789420671761036\n",
      "Batch : 100, Loss : 0.007761679589748383\n",
      "Batch : 110, Loss : 0.0005202513420954347\n",
      "Batch : 120, Loss : 0.0488615557551384\n",
      "Batch : 130, Loss : 0.027365555986762047\n",
      "Batch : 140, Loss : 0.0018418554682284594\n",
      "Batch : 150, Loss : 0.0005843788385391235\n",
      "Batch : 160, Loss : 0.043190158903598785\n",
      "Batch : 170, Loss : 0.0010266227182000875\n",
      "Batch : 180, Loss : 0.05062675476074219\n",
      "Batch : 190, Loss : 0.004201984964311123\n",
      "Batch : 200, Loss : 0.0036289540585130453\n",
      "Batch : 210, Loss : 0.006162137258797884\n",
      "Batch : 220, Loss : 0.0007068386184982955\n",
      "Batch : 230, Loss : 0.006799111608415842\n",
      "Batch : 240, Loss : 0.003926306497305632\n",
      "Batch : 250, Loss : 0.005845639854669571\n",
      "Batch : 260, Loss : 0.0039835525676608086\n",
      "Batch : 270, Loss : 0.0008733152062632143\n",
      "Batch : 280, Loss : 0.0009525216883048415\n",
      "Batch : 290, Loss : 0.009813062846660614\n",
      "Batch : 300, Loss : 0.0005066199810244143\n",
      "Batch : 310, Loss : 7.79900437919423e-05\n",
      "Batch : 320, Loss : 0.0002425615966785699\n",
      "Batch : 330, Loss : 0.0014847542624920607\n",
      "Batch : 340, Loss : 4.292423545848578e-05\n",
      "Batch : 350, Loss : 0.00022424403869081289\n",
      "Batch : 360, Loss : 0.36121097207069397\n",
      "Batch : 370, Loss : 0.11253680288791656\n",
      "Batch : 380, Loss : 0.001900180010125041\n",
      "Batch : 390, Loss : 0.005216197110712528\n",
      "Batch : 400, Loss : 0.022385012358427048\n",
      "Batch : 410, Loss : 0.0027684797532856464\n",
      "Batch : 420, Loss : 0.006648686248809099\n",
      "Batch : 430, Loss : 0.0021276178304105997\n",
      "Batch : 440, Loss : 0.0009708750294521451\n",
      "Batch : 450, Loss : 0.004932799376547337\n",
      "Batch : 460, Loss : 0.011771062389016151\n",
      "Batch : 470, Loss : 0.052124135196208954\n",
      "Batch : 480, Loss : 0.030286040157079697\n",
      "Batch : 490, Loss : 0.030721627175807953\n",
      "Batch : 500, Loss : 0.084255650639534\n",
      "Batch : 510, Loss : 0.0036057631950825453\n",
      "Batch : 520, Loss : 0.0032582974527031183\n",
      "Batch : 530, Loss : 0.013442260213196278\n",
      "Batch : 540, Loss : 0.002244198229163885\n",
      "Batch : 550, Loss : 0.0005779106868430972\n",
      "Batch : 560, Loss : 0.0010100541403517127\n",
      "Batch : 570, Loss : 0.003460182808339596\n",
      "Batch : 580, Loss : 0.003969753161072731\n",
      "Batch : 590, Loss : 0.003298541996628046\n",
      "Batch : 600, Loss : 0.0013180087553337216\n",
      "Batch : 610, Loss : 0.2212754338979721\n",
      "Batch : 620, Loss : 0.00011986988829448819\n",
      "Batch : 630, Loss : 0.003170661861076951\n",
      "Batch : 640, Loss : 0.017181210219860077\n",
      "Batch : 650, Loss : 0.007192918099462986\n",
      "Batch : 660, Loss : 0.000839694170281291\n",
      "Batch : 670, Loss : 0.001033858279697597\n",
      "Batch : 680, Loss : 0.0005337601760402322\n",
      "Batch : 690, Loss : 0.003013644367456436\n",
      "Batch : 700, Loss : 8.474616333842278e-05\n",
      "Batch : 710, Loss : 0.0007424979121424258\n",
      "Batch : 720, Loss : 0.03548461198806763\n",
      "Batch : 730, Loss : 8.998395060189068e-05\n",
      "Batch : 740, Loss : 0.007316062226891518\n",
      "Batch : 750, Loss : 0.0012550659012049437\n",
      "Batch : 760, Loss : 0.0029128589667379856\n",
      "Batch : 770, Loss : 0.07152680307626724\n",
      "Batch : 780, Loss : 0.045470401644706726\n",
      "Batch : 790, Loss : 0.03268691152334213\n",
      "Batch : 800, Loss : 0.013092940673232079\n",
      "Batch : 810, Loss : 0.008426928892731667\n",
      "Batch : 820, Loss : 0.0012529114028438926\n",
      "Batch : 830, Loss : 0.03617265820503235\n",
      "Batch : 840, Loss : 0.04641999304294586\n",
      "Batch : 850, Loss : 0.0594526082277298\n",
      "Batch : 860, Loss : 0.08476347476243973\n",
      "Batch : 870, Loss : 0.004443169571459293\n",
      "Batch : 880, Loss : 0.09989143908023834\n",
      "Batch : 890, Loss : 0.008920579217374325\n",
      "Batch : 900, Loss : 0.0022444159258157015\n",
      "Batch : 910, Loss : 0.0008313650032505393\n",
      "Batch : 920, Loss : 0.0015863798325881362\n",
      "Batch : 930, Loss : 0.003037079004570842\n",
      "Batch : 940, Loss : 0.09560376405715942\n",
      "Batch : 950, Loss : 0.06126631051301956\n",
      "Batch : 960, Loss : 0.3360261917114258\n",
      "Batch : 970, Loss : 0.05335823446512222\n",
      "Batch : 980, Loss : 0.0048310644924640656\n",
      "Batch : 990, Loss : 0.008849428035318851\n",
      "Batch : 1000, Loss : 0.0028735327068716288\n",
      "Batch : 1010, Loss : 0.21576577425003052\n",
      "Batch : 1020, Loss : 0.014705542474985123\n",
      "Batch : 1030, Loss : 0.026605652645230293\n",
      "Batch : 1040, Loss : 0.005127029027789831\n",
      "Batch : 1050, Loss : 0.004865413065999746\n",
      "Batch : 1060, Loss : 0.007009486202150583\n",
      "Batch : 1070, Loss : 0.011677544564008713\n",
      "Batch : 1080, Loss : 0.013698849827051163\n",
      "Batch : 1090, Loss : 0.009908193722367287\n",
      "Batch : 1100, Loss : 0.05398736149072647\n",
      "Batch : 1110, Loss : 0.02054525725543499\n",
      "Batch : 1120, Loss : 0.06378260254859924\n",
      "Batch : 1130, Loss : 0.0026090594474226236\n",
      "Batch : 1140, Loss : 0.07484559714794159\n",
      "Batch : 1150, Loss : 0.009283051826059818\n",
      "Batch : 1160, Loss : 0.0018412477802485228\n",
      "Batch : 1170, Loss : 0.0017930243629962206\n",
      "Batch : 1180, Loss : 0.00019729661289602518\n",
      "Batch : 1190, Loss : 0.0019510064739733934\n",
      "Batch : 1200, Loss : 0.0002229622914455831\n",
      "Batch : 1210, Loss : 0.006461030803620815\n",
      "Batch : 1220, Loss : 0.0022330847568809986\n",
      "Batch : 1230, Loss : 0.07829418778419495\n",
      "Batch : 1240, Loss : 0.13962163031101227\n",
      "Batch : 1250, Loss : 0.1760636270046234\n",
      "Batch : 1260, Loss : 0.0001678955159150064\n",
      "Batch : 1270, Loss : 0.03290243446826935\n",
      "Batch : 1280, Loss : 0.0005580692668445408\n",
      "Batch : 1290, Loss : 0.004024918656796217\n",
      "Batch : 1300, Loss : 0.0009679458453319967\n",
      "Batch : 1310, Loss : 0.11103180795907974\n",
      "Batch : 1320, Loss : 0.004704208113253117\n",
      "Batch : 1330, Loss : 0.0023304361384361982\n",
      "Batch : 1340, Loss : 0.15098340809345245\n",
      "Batch : 1350, Loss : 0.00019007609807886183\n",
      "Batch : 1360, Loss : 0.015240290202200413\n",
      "Batch : 1370, Loss : 0.13854119181632996\n",
      "Batch : 1380, Loss : 0.009598756209015846\n",
      "Batch : 1390, Loss : 0.006074683275073767\n",
      "Batch : 1400, Loss : 0.004232202190905809\n",
      "Batch : 1410, Loss : 0.006382927298545837\n",
      "Batch : 1420, Loss : 0.0062148491851985455\n",
      "Batch : 1430, Loss : 0.0022161139640957117\n",
      "Batch : 1440, Loss : 0.0018979627639055252\n",
      "Batch : 1450, Loss : 0.001644624164327979\n",
      "Batch : 1460, Loss : 0.1341099888086319\n",
      "Batch : 1470, Loss : 0.04892028868198395\n",
      "Batch : 1480, Loss : 0.0019351793453097343\n",
      "Batch : 1490, Loss : 0.029783910140395164\n",
      "Batch : 1500, Loss : 0.001426369184628129\n",
      "Batch : 1510, Loss : 0.0295407697558403\n",
      "Batch : 1520, Loss : 0.0028097021859139204\n",
      "Batch : 1530, Loss : 0.0018463090527802706\n",
      "Batch : 1540, Loss : 0.02925020270049572\n",
      "Batch : 1550, Loss : 0.016204148530960083\n",
      "Batch : 1560, Loss : 0.12692628800868988\n",
      "Batch : 1570, Loss : 0.03313618153333664\n",
      "Batch : 1580, Loss : 0.00251231761649251\n",
      "Batch : 1590, Loss : 0.021382536739110947\n",
      "Batch : 1600, Loss : 0.02169976383447647\n",
      "Batch : 1610, Loss : 0.03001604601740837\n",
      "Batch : 1620, Loss : 0.002632834017276764\n",
      "Batch : 1630, Loss : 0.12181447446346283\n",
      "Batch : 1640, Loss : 0.005208165384829044\n",
      "Batch : 1650, Loss : 0.21766699850559235\n",
      "Batch : 1660, Loss : 0.05127294734120369\n",
      "Batch : 1670, Loss : 0.08571284264326096\n",
      "Batch : 1680, Loss : 0.001859126496128738\n",
      "Batch : 1690, Loss : 0.0005712585407309234\n",
      "Batch : 1700, Loss : 0.007017809897661209\n",
      "Batch : 1710, Loss : 0.012377282604575157\n",
      "Batch : 1720, Loss : 0.018734809011220932\n",
      "Batch : 1730, Loss : 0.0029220469295978546\n",
      "Batch : 1740, Loss : 0.1926005482673645\n",
      "Batch : 1750, Loss : 0.0028745359741151333\n",
      "Batch : 1760, Loss : 0.07033007591962814\n",
      "Batch : 1770, Loss : 0.000868988165166229\n",
      "Batch : 1780, Loss : 0.0008937721722759306\n",
      "Batch : 1790, Loss : 0.0002171401574742049\n",
      "Batch : 1800, Loss : 0.0024880091659724712\n",
      "Batch : 1810, Loss : 0.000660977850202471\n",
      "Batch : 1820, Loss : 0.0780971497297287\n",
      "Batch : 1830, Loss : 0.0007371167303062975\n",
      "Batch : 1840, Loss : 0.0430821068584919\n",
      "Batch : 1850, Loss : 0.0002103983861161396\n",
      "Batch : 1860, Loss : 0.0018952962709590793\n",
      "Batch : 1870, Loss : 0.0009009010391309857\n",
      "Epoch : 5\n",
      "Batch : 0, Loss : 0.0003453180834185332\n",
      "Batch : 10, Loss : 0.0008166717598214746\n",
      "Batch : 20, Loss : 0.0003802725113928318\n",
      "Batch : 30, Loss : 0.005006785038858652\n",
      "Batch : 40, Loss : 0.0008301236666738987\n",
      "Batch : 50, Loss : 0.0005998968263156712\n",
      "Batch : 60, Loss : 0.003702237270772457\n",
      "Batch : 70, Loss : 0.001035509048961103\n",
      "Batch : 80, Loss : 0.004420854151248932\n",
      "Batch : 90, Loss : 0.005227892659604549\n",
      "Batch : 100, Loss : 0.00027637515449896455\n",
      "Batch : 110, Loss : 0.16292010247707367\n",
      "Batch : 120, Loss : 0.0027753105387091637\n",
      "Batch : 130, Loss : 0.01830207370221615\n",
      "Batch : 140, Loss : 0.007447918877005577\n",
      "Batch : 150, Loss : 0.01077852863818407\n",
      "Batch : 160, Loss : 0.001105321105569601\n",
      "Batch : 170, Loss : 0.13957814872264862\n",
      "Batch : 180, Loss : 0.005241432227194309\n",
      "Batch : 190, Loss : 0.019568705931305885\n",
      "Batch : 200, Loss : 0.0024946227204054594\n",
      "Batch : 210, Loss : 0.0026110834442079067\n",
      "Batch : 220, Loss : 0.024596357718110085\n",
      "Batch : 230, Loss : 0.011053217574954033\n",
      "Batch : 240, Loss : 0.00020470206800382584\n",
      "Batch : 250, Loss : 0.0037212136667221785\n",
      "Batch : 260, Loss : 0.03315060958266258\n",
      "Batch : 270, Loss : 0.005926676094532013\n",
      "Batch : 280, Loss : 0.006209874525666237\n",
      "Batch : 290, Loss : 0.049229804426431656\n",
      "Batch : 300, Loss : 0.007598253432661295\n",
      "Batch : 310, Loss : 0.001882266835309565\n",
      "Batch : 320, Loss : 0.005296210292726755\n",
      "Batch : 330, Loss : 0.0003001269942615181\n",
      "Batch : 340, Loss : 0.002184818033128977\n",
      "Batch : 350, Loss : 0.10112743079662323\n",
      "Batch : 360, Loss : 0.0008040317916311324\n",
      "Batch : 370, Loss : 0.00012412952492013574\n",
      "Batch : 380, Loss : 0.0008567534969188273\n",
      "Batch : 390, Loss : 0.0002798872592393309\n",
      "Batch : 400, Loss : 0.06764788925647736\n",
      "Batch : 410, Loss : 0.008835209533572197\n",
      "Batch : 420, Loss : 0.0005034439382143319\n",
      "Batch : 430, Loss : 0.024781260639429092\n",
      "Batch : 440, Loss : 0.11166398972272873\n",
      "Batch : 450, Loss : 0.0010134808253496885\n",
      "Batch : 460, Loss : 0.0013104680692777038\n",
      "Batch : 470, Loss : 0.16686725616455078\n",
      "Batch : 480, Loss : 0.005450689699500799\n",
      "Batch : 490, Loss : 0.015301325358450413\n",
      "Batch : 500, Loss : 0.00024632710847072303\n",
      "Batch : 510, Loss : 0.0011558678233996034\n",
      "Batch : 520, Loss : 0.0029345916118472815\n",
      "Batch : 530, Loss : 0.00428056251257658\n",
      "Batch : 540, Loss : 0.05953853204846382\n",
      "Batch : 550, Loss : 0.019414735957980156\n",
      "Batch : 560, Loss : 0.00107108848169446\n",
      "Batch : 570, Loss : 0.00875938031822443\n",
      "Batch : 580, Loss : 0.012943490408360958\n",
      "Batch : 590, Loss : 0.00010545925033511594\n",
      "Batch : 600, Loss : 0.042269110679626465\n",
      "Batch : 610, Loss : 0.0019107904518023133\n",
      "Batch : 620, Loss : 0.0044679949060082436\n",
      "Batch : 630, Loss : 0.004368251655250788\n",
      "Batch : 640, Loss : 0.00010529320570640266\n",
      "Batch : 650, Loss : 4.527803321252577e-05\n",
      "Batch : 660, Loss : 0.00575250294059515\n",
      "Batch : 670, Loss : 0.0001307727216044441\n",
      "Batch : 680, Loss : 0.061127640306949615\n",
      "Batch : 690, Loss : 0.00010605636634863913\n",
      "Batch : 700, Loss : 0.0022162548266351223\n",
      "Batch : 710, Loss : 0.0050690434873104095\n",
      "Batch : 720, Loss : 2.153118111891672e-05\n",
      "Batch : 730, Loss : 0.05118916928768158\n",
      "Batch : 740, Loss : 0.0007655507652089\n",
      "Batch : 750, Loss : 0.0005274581490084529\n",
      "Batch : 760, Loss : 0.0015086940256878734\n",
      "Batch : 770, Loss : 0.03076701983809471\n",
      "Batch : 780, Loss : 0.005813064053654671\n",
      "Batch : 790, Loss : 3.9304326492128894e-05\n",
      "Batch : 800, Loss : 0.0029937303625047207\n",
      "Batch : 810, Loss : 0.010332483798265457\n",
      "Batch : 820, Loss : 0.002573069417849183\n",
      "Batch : 830, Loss : 0.0007468080148100853\n",
      "Batch : 840, Loss : 0.009593648836016655\n",
      "Batch : 850, Loss : 0.0028100896161049604\n",
      "Batch : 860, Loss : 0.12036366015672684\n",
      "Batch : 870, Loss : 0.06539908796548843\n",
      "Batch : 880, Loss : 0.01859387382864952\n",
      "Batch : 890, Loss : 0.038575951009988785\n",
      "Batch : 900, Loss : 0.03472618758678436\n",
      "Batch : 910, Loss : 0.019381245598196983\n",
      "Batch : 920, Loss : 0.011807238683104515\n",
      "Batch : 930, Loss : 0.00015183319919742644\n",
      "Batch : 940, Loss : 0.0027632741257548332\n",
      "Batch : 950, Loss : 2.4564418708905578e-05\n",
      "Batch : 960, Loss : 0.003478064201772213\n",
      "Batch : 970, Loss : 0.00011002379324054345\n",
      "Batch : 980, Loss : 0.02513010986149311\n",
      "Batch : 990, Loss : 0.002543751848861575\n",
      "Batch : 1000, Loss : 0.0034926235675811768\n",
      "Batch : 1010, Loss : 0.00026330846594646573\n",
      "Batch : 1020, Loss : 0.0003718837979249656\n",
      "Batch : 1030, Loss : 0.007174224592745304\n",
      "Batch : 1040, Loss : 0.0013146238634362817\n",
      "Batch : 1050, Loss : 0.00013691754429601133\n",
      "Batch : 1060, Loss : 0.0006039999425411224\n",
      "Batch : 1070, Loss : 0.004509530030190945\n",
      "Batch : 1080, Loss : 0.01015818864107132\n",
      "Batch : 1090, Loss : 0.006462431512773037\n",
      "Batch : 1100, Loss : 0.0003174370795022696\n",
      "Batch : 1110, Loss : 0.27791664004325867\n",
      "Batch : 1120, Loss : 0.032319363206624985\n",
      "Batch : 1130, Loss : 0.0006005317554809153\n",
      "Batch : 1140, Loss : 0.02878567762672901\n",
      "Batch : 1150, Loss : 0.00012259521463420242\n",
      "Batch : 1160, Loss : 0.014399625360965729\n",
      "Batch : 1170, Loss : 0.005626908969134092\n",
      "Batch : 1180, Loss : 0.0006236117915250361\n",
      "Batch : 1190, Loss : 0.009303354658186436\n",
      "Batch : 1200, Loss : 0.00010781604214571416\n",
      "Batch : 1210, Loss : 0.020078185945749283\n",
      "Batch : 1220, Loss : 0.04334188997745514\n",
      "Batch : 1230, Loss : 0.0026040622033178806\n",
      "Batch : 1240, Loss : 0.005847137421369553\n",
      "Batch : 1250, Loss : 0.0010775360278785229\n",
      "Batch : 1260, Loss : 0.014770117588341236\n",
      "Batch : 1270, Loss : 0.0001232362847076729\n",
      "Batch : 1280, Loss : 0.0192743930965662\n",
      "Batch : 1290, Loss : 0.007286792621016502\n",
      "Batch : 1300, Loss : 0.10673562437295914\n",
      "Batch : 1310, Loss : 0.0009034733520820737\n",
      "Batch : 1320, Loss : 0.0016930988058447838\n",
      "Batch : 1330, Loss : 0.0025407199282199144\n",
      "Batch : 1340, Loss : 0.0052910251542925835\n",
      "Batch : 1350, Loss : 0.0004680373822338879\n",
      "Batch : 1360, Loss : 0.0002282655332237482\n",
      "Batch : 1370, Loss : 0.0014816352631896734\n",
      "Batch : 1380, Loss : 0.13718168437480927\n",
      "Batch : 1390, Loss : 0.021225187927484512\n",
      "Batch : 1400, Loss : 0.001641322043724358\n",
      "Batch : 1410, Loss : 0.02512522041797638\n",
      "Batch : 1420, Loss : 0.0006502039614133537\n",
      "Batch : 1430, Loss : 0.00919707678258419\n",
      "Batch : 1440, Loss : 0.00355736562050879\n",
      "Batch : 1450, Loss : 0.012086690403521061\n",
      "Batch : 1460, Loss : 0.008490032516419888\n",
      "Batch : 1470, Loss : 0.06768462061882019\n",
      "Batch : 1480, Loss : 0.001882757293060422\n",
      "Batch : 1490, Loss : 0.0005571168148890138\n",
      "Batch : 1500, Loss : 0.002726720878854394\n",
      "Batch : 1510, Loss : 0.009427969343960285\n",
      "Batch : 1520, Loss : 0.0005869307788088918\n",
      "Batch : 1530, Loss : 0.007449905388057232\n",
      "Batch : 1540, Loss : 0.00026481106760911644\n",
      "Batch : 1550, Loss : 0.05313757434487343\n",
      "Batch : 1560, Loss : 0.0007148252916522324\n",
      "Batch : 1570, Loss : 0.0045232512056827545\n",
      "Batch : 1580, Loss : 0.0006210474530234933\n",
      "Batch : 1590, Loss : 0.00012757749937009066\n",
      "Batch : 1600, Loss : 0.1577722132205963\n",
      "Batch : 1610, Loss : 0.010653839446604252\n",
      "Batch : 1620, Loss : 0.002131824381649494\n",
      "Batch : 1630, Loss : 0.00012610330304596573\n",
      "Batch : 1640, Loss : 0.00011360688222339377\n",
      "Batch : 1650, Loss : 0.002461724914610386\n",
      "Batch : 1660, Loss : 0.0017615503165870905\n",
      "Batch : 1670, Loss : 0.0006408592453226447\n",
      "Batch : 1680, Loss : 0.00613162387162447\n",
      "Batch : 1690, Loss : 0.014360232278704643\n",
      "Batch : 1700, Loss : 0.009378624148666859\n",
      "Batch : 1710, Loss : 0.01724407449364662\n",
      "Batch : 1720, Loss : 0.042528532445430756\n",
      "Batch : 1730, Loss : 0.044657252728939056\n",
      "Batch : 1740, Loss : 0.05495322868227959\n",
      "Batch : 1750, Loss : 0.0011735919397324324\n",
      "Batch : 1760, Loss : 0.0010986806591972709\n",
      "Batch : 1770, Loss : 0.0005566113395616412\n",
      "Batch : 1780, Loss : 0.003537324257194996\n",
      "Batch : 1790, Loss : 0.0028450654353946447\n",
      "Batch : 1800, Loss : 0.00046587971155531704\n",
      "Batch : 1810, Loss : 0.006576097570359707\n",
      "Batch : 1820, Loss : 0.009889280423521996\n",
      "Batch : 1830, Loss : 0.0016434787539765239\n",
      "Batch : 1840, Loss : 0.0003350989136379212\n",
      "Batch : 1850, Loss : 0.06784673035144806\n",
      "Batch : 1860, Loss : 0.1064838394522667\n",
      "Batch : 1870, Loss : 0.0026689295191317797\n",
      "Epoch : 6\n",
      "Batch : 0, Loss : 0.006731473375111818\n",
      "Batch : 10, Loss : 0.008389802649617195\n",
      "Batch : 20, Loss : 0.00047015296877361834\n",
      "Batch : 30, Loss : 0.18744845688343048\n",
      "Batch : 40, Loss : 0.00022660617833025753\n",
      "Batch : 50, Loss : 0.002150775631889701\n",
      "Batch : 60, Loss : 0.11631572991609573\n",
      "Batch : 70, Loss : 5.441272514872253e-05\n",
      "Batch : 80, Loss : 0.020604407414793968\n",
      "Batch : 90, Loss : 0.007104701828211546\n",
      "Batch : 100, Loss : 0.0005187700153328478\n",
      "Batch : 110, Loss : 0.0004020832711830735\n",
      "Batch : 120, Loss : 0.0003402176371309906\n",
      "Batch : 130, Loss : 0.006835063919425011\n",
      "Batch : 140, Loss : 0.07226422429084778\n",
      "Batch : 150, Loss : 0.0042679086327552795\n",
      "Batch : 160, Loss : 0.0023876046761870384\n",
      "Batch : 170, Loss : 0.000796145701315254\n",
      "Batch : 180, Loss : 0.002141546458005905\n",
      "Batch : 190, Loss : 0.006397842895239592\n",
      "Batch : 200, Loss : 0.004457860719412565\n",
      "Batch : 210, Loss : 0.000696814910043031\n",
      "Batch : 220, Loss : 0.046601515263319016\n",
      "Batch : 230, Loss : 0.037833862006664276\n",
      "Batch : 240, Loss : 0.06185062974691391\n",
      "Batch : 250, Loss : 0.013713343068957329\n",
      "Batch : 260, Loss : 0.0009827080648392439\n",
      "Batch : 270, Loss : 0.0062232171185314655\n",
      "Batch : 280, Loss : 0.035409748554229736\n",
      "Batch : 290, Loss : 3.622044823714532e-05\n",
      "Batch : 300, Loss : 0.0024979780428111553\n",
      "Batch : 310, Loss : 0.0035004375968128443\n",
      "Batch : 320, Loss : 0.0003381780697964132\n",
      "Batch : 330, Loss : 0.01954731158912182\n",
      "Batch : 340, Loss : 0.003938696347177029\n",
      "Batch : 350, Loss : 0.0009214258752763271\n",
      "Batch : 360, Loss : 0.00050878751790151\n",
      "Batch : 370, Loss : 0.0011131670325994492\n",
      "Batch : 380, Loss : 0.002290717326104641\n",
      "Batch : 390, Loss : 0.018637152388691902\n",
      "Batch : 400, Loss : 5.0402227316226345e-06\n",
      "Batch : 410, Loss : 6.244031101232395e-05\n",
      "Batch : 420, Loss : 0.0003715105995070189\n",
      "Batch : 430, Loss : 0.004200669936835766\n",
      "Batch : 440, Loss : 4.2657091398723423e-05\n",
      "Batch : 450, Loss : 0.011089662089943886\n",
      "Batch : 460, Loss : 0.011496778577566147\n",
      "Batch : 470, Loss : 0.00019862210319843143\n",
      "Batch : 480, Loss : 0.017193499952554703\n",
      "Batch : 490, Loss : 0.002968847518786788\n",
      "Batch : 500, Loss : 0.00046084937639534473\n",
      "Batch : 510, Loss : 0.0012744390405714512\n",
      "Batch : 520, Loss : 0.18952080607414246\n",
      "Batch : 530, Loss : 0.0007294156239368021\n",
      "Batch : 540, Loss : 0.0013160421513020992\n",
      "Batch : 550, Loss : 0.0005586176412180066\n",
      "Batch : 560, Loss : 0.00029358002939261496\n",
      "Batch : 570, Loss : 0.02270554006099701\n",
      "Batch : 580, Loss : 0.00011159911809954792\n",
      "Batch : 590, Loss : 0.0005888135638087988\n",
      "Batch : 600, Loss : 7.375189306912944e-05\n",
      "Batch : 610, Loss : 0.0002847130235750228\n",
      "Batch : 620, Loss : 0.0011698752641677856\n",
      "Batch : 630, Loss : 0.00047041993821039796\n",
      "Batch : 640, Loss : 0.0030121845193207264\n",
      "Batch : 650, Loss : 0.0011277245357632637\n",
      "Batch : 660, Loss : 0.00016823163605295122\n",
      "Batch : 670, Loss : 0.004101028200238943\n",
      "Batch : 680, Loss : 0.0049486965872347355\n",
      "Batch : 690, Loss : 0.00023331129341386259\n",
      "Batch : 700, Loss : 0.005118259694427252\n",
      "Batch : 710, Loss : 0.0064478591084480286\n",
      "Batch : 720, Loss : 0.0002685338258743286\n",
      "Batch : 730, Loss : 0.0002596195263322443\n",
      "Batch : 740, Loss : 0.00047761661699041724\n",
      "Batch : 750, Loss : 0.0018433888908475637\n",
      "Batch : 760, Loss : 0.0017450626473873854\n",
      "Batch : 770, Loss : 0.001089002238586545\n",
      "Batch : 780, Loss : 0.07354329526424408\n",
      "Batch : 790, Loss : 7.512531010434031e-05\n",
      "Batch : 800, Loss : 1.5319745216402225e-05\n",
      "Batch : 810, Loss : 0.0040337988175451756\n",
      "Batch : 820, Loss : 0.022838717326521873\n",
      "Batch : 830, Loss : 8.096468081930652e-05\n",
      "Batch : 840, Loss : 0.08699347823858261\n",
      "Batch : 850, Loss : 0.014629984274506569\n",
      "Batch : 860, Loss : 5.9737201809184626e-05\n",
      "Batch : 870, Loss : 0.0008854256011545658\n",
      "Batch : 880, Loss : 0.000938905228395015\n",
      "Batch : 890, Loss : 9.759195381775498e-05\n",
      "Batch : 900, Loss : 0.0025782734155654907\n",
      "Batch : 910, Loss : 0.020794127136468887\n",
      "Batch : 920, Loss : 0.0003865338221658021\n",
      "Batch : 930, Loss : 0.0003754289064090699\n",
      "Batch : 940, Loss : 0.0014841763768345118\n",
      "Batch : 950, Loss : 0.017672887071967125\n",
      "Batch : 960, Loss : 0.002098123775795102\n",
      "Batch : 970, Loss : 0.16811329126358032\n",
      "Batch : 980, Loss : 1.1114809240098111e-05\n",
      "Batch : 990, Loss : 0.002635677345097065\n",
      "Batch : 1000, Loss : 0.007979712449014187\n",
      "Batch : 1010, Loss : 0.06304369866847992\n",
      "Batch : 1020, Loss : 0.0036100074648857117\n",
      "Batch : 1030, Loss : 0.008054402656853199\n",
      "Batch : 1040, Loss : 0.0006015849648974836\n",
      "Batch : 1050, Loss : 0.000592126336414367\n",
      "Batch : 1060, Loss : 0.0010217188391834497\n",
      "Batch : 1070, Loss : 0.12071149796247482\n",
      "Batch : 1080, Loss : 0.0006760161486454308\n",
      "Batch : 1090, Loss : 0.010097779333591461\n",
      "Batch : 1100, Loss : 0.005444847512990236\n",
      "Batch : 1110, Loss : 0.0016673794016242027\n",
      "Batch : 1120, Loss : 0.0008823304087854922\n",
      "Batch : 1130, Loss : 0.14266656339168549\n",
      "Batch : 1140, Loss : 0.21197892725467682\n",
      "Batch : 1150, Loss : 0.009868782944977283\n",
      "Batch : 1160, Loss : 0.1717396229505539\n",
      "Batch : 1170, Loss : 0.06415165215730667\n",
      "Batch : 1180, Loss : 0.051055505871772766\n",
      "Batch : 1190, Loss : 0.00012468083878047764\n",
      "Batch : 1200, Loss : 0.061034638434648514\n",
      "Batch : 1210, Loss : 0.00013535386824514717\n",
      "Batch : 1220, Loss : 8.398533100262284e-05\n",
      "Batch : 1230, Loss : 0.004721102770417929\n",
      "Batch : 1240, Loss : 0.013518543913960457\n",
      "Batch : 1250, Loss : 0.0007538218051195145\n",
      "Batch : 1260, Loss : 0.050436120480298996\n",
      "Batch : 1270, Loss : 0.00036115897819399834\n",
      "Batch : 1280, Loss : 0.000354287913069129\n",
      "Batch : 1290, Loss : 0.006119916681200266\n",
      "Batch : 1300, Loss : 0.02384895272552967\n",
      "Batch : 1310, Loss : 0.00044865612289868295\n",
      "Batch : 1320, Loss : 0.003177052829414606\n",
      "Batch : 1330, Loss : 0.10361985117197037\n",
      "Batch : 1340, Loss : 0.002943821484223008\n",
      "Batch : 1350, Loss : 0.09176447987556458\n",
      "Batch : 1360, Loss : 0.0016747356858104467\n",
      "Batch : 1370, Loss : 0.001209203153848648\n",
      "Batch : 1380, Loss : 0.0035403387155383825\n",
      "Batch : 1390, Loss : 0.007950924336910248\n",
      "Batch : 1400, Loss : 0.03873266652226448\n",
      "Batch : 1410, Loss : 0.017961392179131508\n",
      "Batch : 1420, Loss : 0.04881802946329117\n",
      "Batch : 1430, Loss : 0.00031106011010706425\n",
      "Batch : 1440, Loss : 0.06837756931781769\n",
      "Batch : 1450, Loss : 7.580628152936697e-05\n",
      "Batch : 1460, Loss : 0.0512881763279438\n",
      "Batch : 1470, Loss : 0.011779368855059147\n",
      "Batch : 1480, Loss : 0.00032346416264772415\n",
      "Batch : 1490, Loss : 0.0005180109874345362\n",
      "Batch : 1500, Loss : 0.0012862704461440444\n",
      "Batch : 1510, Loss : 0.0008108860347419977\n",
      "Batch : 1520, Loss : 0.10664866119623184\n",
      "Batch : 1530, Loss : 2.5322422516182996e-05\n",
      "Batch : 1540, Loss : 0.005303656682372093\n",
      "Batch : 1550, Loss : 0.09209751337766647\n",
      "Batch : 1560, Loss : 0.009002142585814\n",
      "Batch : 1570, Loss : 0.0001756638230290264\n",
      "Batch : 1580, Loss : 0.0009501003660261631\n",
      "Batch : 1590, Loss : 0.00043292687041684985\n",
      "Batch : 1600, Loss : 0.0816883072257042\n",
      "Batch : 1610, Loss : 0.002013854216784239\n",
      "Batch : 1620, Loss : 0.00026974809588864446\n",
      "Batch : 1630, Loss : 0.00021416504750959575\n",
      "Batch : 1640, Loss : 0.2610146999359131\n",
      "Batch : 1650, Loss : 0.003471443196758628\n",
      "Batch : 1660, Loss : 0.026325726881623268\n",
      "Batch : 1670, Loss : 0.005435936152935028\n",
      "Batch : 1680, Loss : 7.533129246439785e-05\n",
      "Batch : 1690, Loss : 0.004822210408747196\n",
      "Batch : 1700, Loss : 0.024986764416098595\n",
      "Batch : 1710, Loss : 0.014495906420052052\n",
      "Batch : 1720, Loss : 0.06366968899965286\n",
      "Batch : 1730, Loss : 0.056146323680877686\n",
      "Batch : 1740, Loss : 0.001013609697110951\n",
      "Batch : 1750, Loss : 0.002109797904267907\n",
      "Batch : 1760, Loss : 0.005030184518545866\n",
      "Batch : 1770, Loss : 0.021484803408384323\n",
      "Batch : 1780, Loss : 1.1789978998422157e-05\n",
      "Batch : 1790, Loss : 0.021999256685376167\n",
      "Batch : 1800, Loss : 0.011759085580706596\n",
      "Batch : 1810, Loss : 0.01528852991759777\n",
      "Batch : 1820, Loss : 0.0005563785671256483\n",
      "Batch : 1830, Loss : 0.0002160961739718914\n",
      "Batch : 1840, Loss : 0.0005456825019791722\n",
      "Batch : 1850, Loss : 0.0012717684730887413\n",
      "Batch : 1860, Loss : 0.1442873477935791\n",
      "Batch : 1870, Loss : 0.00031081735505722463\n",
      "Epoch : 7\n",
      "Batch : 0, Loss : 0.0971158817410469\n",
      "Batch : 10, Loss : 0.001128029776737094\n",
      "Batch : 20, Loss : 0.0002874880447052419\n",
      "Batch : 30, Loss : 0.00024361754185520113\n",
      "Batch : 40, Loss : 0.003730673575773835\n",
      "Batch : 50, Loss : 0.0005470545729622245\n",
      "Batch : 60, Loss : 0.0041300030425190926\n",
      "Batch : 70, Loss : 0.000568821036722511\n",
      "Batch : 80, Loss : 0.1361338496208191\n",
      "Batch : 90, Loss : 3.687658318085596e-05\n",
      "Batch : 100, Loss : 5.3097483032615855e-05\n",
      "Batch : 110, Loss : 0.07331062853336334\n",
      "Batch : 120, Loss : 0.0009585763327777386\n",
      "Batch : 130, Loss : 0.038650695234537125\n",
      "Batch : 140, Loss : 4.5953362132422626e-05\n",
      "Batch : 150, Loss : 0.000880949548445642\n",
      "Batch : 160, Loss : 0.03304295986890793\n",
      "Batch : 170, Loss : 0.011736719869077206\n",
      "Batch : 180, Loss : 0.0013552732998505235\n",
      "Batch : 190, Loss : 0.0015835955273360014\n",
      "Batch : 200, Loss : 0.040192171931266785\n",
      "Batch : 210, Loss : 0.00015206071839202195\n",
      "Batch : 220, Loss : 0.0009034102549776435\n",
      "Batch : 230, Loss : 0.03636365011334419\n",
      "Batch : 240, Loss : 0.0020895854104310274\n",
      "Batch : 250, Loss : 0.009900560602545738\n",
      "Batch : 260, Loss : 0.016023758798837662\n",
      "Batch : 270, Loss : 0.0027403030544519424\n",
      "Batch : 280, Loss : 0.003282990539446473\n",
      "Batch : 290, Loss : 0.000526732299476862\n",
      "Batch : 300, Loss : 0.004890045151114464\n",
      "Batch : 310, Loss : 0.003826398402452469\n",
      "Batch : 320, Loss : 0.027699895203113556\n",
      "Batch : 330, Loss : 0.001265950151719153\n",
      "Batch : 340, Loss : 0.14385223388671875\n",
      "Batch : 350, Loss : 0.05225644260644913\n",
      "Batch : 360, Loss : 0.0010029857512563467\n",
      "Batch : 370, Loss : 0.0017175647662952542\n",
      "Batch : 380, Loss : 0.013710214756429195\n",
      "Batch : 390, Loss : 0.04406987503170967\n",
      "Batch : 400, Loss : 0.00024669061531312764\n",
      "Batch : 410, Loss : 0.0021556601859629154\n",
      "Batch : 420, Loss : 0.02801312506198883\n",
      "Batch : 430, Loss : 0.0017986480379477143\n",
      "Batch : 440, Loss : 0.0004128142318222672\n",
      "Batch : 450, Loss : 0.00024055034737102687\n",
      "Batch : 460, Loss : 0.08187559992074966\n",
      "Batch : 470, Loss : 0.0001913579908432439\n",
      "Batch : 480, Loss : 0.00012949494703207165\n",
      "Batch : 490, Loss : 0.003341545118018985\n",
      "Batch : 500, Loss : 0.008078249171376228\n",
      "Batch : 510, Loss : 0.002636500634253025\n",
      "Batch : 520, Loss : 0.057900603860616684\n",
      "Batch : 530, Loss : 0.019454704597592354\n",
      "Batch : 540, Loss : 0.0013187488075345755\n",
      "Batch : 550, Loss : 0.23976530134677887\n",
      "Batch : 560, Loss : 0.042120274156332016\n",
      "Batch : 570, Loss : 0.015923582017421722\n",
      "Batch : 580, Loss : 2.7719010176951997e-05\n",
      "Batch : 590, Loss : 0.00023049204901326448\n",
      "Batch : 600, Loss : 0.022254187613725662\n",
      "Batch : 610, Loss : 0.016300048679113388\n",
      "Batch : 620, Loss : 0.2419373244047165\n",
      "Batch : 630, Loss : 0.00244219065643847\n",
      "Batch : 640, Loss : 0.0007364615448750556\n",
      "Batch : 650, Loss : 0.00036933147930540144\n",
      "Batch : 660, Loss : 0.00010066146933240816\n",
      "Batch : 670, Loss : 0.060843564569950104\n",
      "Batch : 680, Loss : 0.010810168460011482\n",
      "Batch : 690, Loss : 0.002411341294646263\n",
      "Batch : 700, Loss : 0.004461649339646101\n",
      "Batch : 710, Loss : 0.00034684635465964675\n",
      "Batch : 720, Loss : 4.5687760575674474e-05\n",
      "Batch : 730, Loss : 0.005862426944077015\n",
      "Batch : 740, Loss : 0.00207322183996439\n",
      "Batch : 750, Loss : 0.05780472978949547\n",
      "Batch : 760, Loss : 0.05966949835419655\n",
      "Batch : 770, Loss : 0.010876097716391087\n",
      "Batch : 780, Loss : 0.16427506506443024\n",
      "Batch : 790, Loss : 0.00039096185355447233\n",
      "Batch : 800, Loss : 0.000945627165492624\n",
      "Batch : 810, Loss : 0.05053018406033516\n",
      "Batch : 820, Loss : 0.0024364865384995937\n",
      "Batch : 830, Loss : 0.004235708620399237\n",
      "Batch : 840, Loss : 0.025681203231215477\n",
      "Batch : 850, Loss : 1.2343942216830328e-05\n",
      "Batch : 860, Loss : 0.007173240650445223\n",
      "Batch : 870, Loss : 0.0028163876850157976\n",
      "Batch : 880, Loss : 0.22640164196491241\n",
      "Batch : 890, Loss : 0.03593797609210014\n",
      "Batch : 900, Loss : 0.0004109297879040241\n",
      "Batch : 910, Loss : 0.0007795029086992145\n",
      "Batch : 920, Loss : 0.0003282372490502894\n",
      "Batch : 930, Loss : 0.003142471192404628\n",
      "Batch : 940, Loss : 0.0008804607205092907\n",
      "Batch : 950, Loss : 0.006674300879240036\n",
      "Batch : 960, Loss : 0.0003518995363265276\n",
      "Batch : 970, Loss : 0.000488828809466213\n",
      "Batch : 980, Loss : 0.0001567252038512379\n",
      "Batch : 990, Loss : 0.026182739064097404\n",
      "Batch : 1000, Loss : 0.001985285896807909\n",
      "Batch : 1010, Loss : 0.00993618555366993\n",
      "Batch : 1020, Loss : 0.0128590427339077\n",
      "Batch : 1030, Loss : 0.02760556899011135\n",
      "Batch : 1040, Loss : 1.672410508035682e-05\n",
      "Batch : 1050, Loss : 0.001807088847272098\n",
      "Batch : 1060, Loss : 0.0010916716419160366\n",
      "Batch : 1070, Loss : 0.02211940661072731\n",
      "Batch : 1080, Loss : 0.001009603962302208\n",
      "Batch : 1090, Loss : 0.001190906041301787\n",
      "Batch : 1100, Loss : 0.008560963906347752\n",
      "Batch : 1110, Loss : 0.004918836057186127\n",
      "Batch : 1120, Loss : 0.023339768871665\n",
      "Batch : 1130, Loss : 0.00101462344173342\n",
      "Batch : 1140, Loss : 0.0010558611247688532\n",
      "Batch : 1150, Loss : 0.031799301505088806\n",
      "Batch : 1160, Loss : 0.000606405723374337\n",
      "Batch : 1170, Loss : 0.00011508597526699305\n",
      "Batch : 1180, Loss : 0.003200043458491564\n",
      "Batch : 1190, Loss : 9.258331556338817e-05\n",
      "Batch : 1200, Loss : 3.225840555387549e-05\n",
      "Batch : 1210, Loss : 9.825009328778833e-05\n",
      "Batch : 1220, Loss : 0.03394826129078865\n",
      "Batch : 1230, Loss : 0.00022342641022987664\n",
      "Batch : 1240, Loss : 0.001197019242681563\n",
      "Batch : 1250, Loss : 0.018864871934056282\n",
      "Batch : 1260, Loss : 0.0070640756748616695\n",
      "Batch : 1270, Loss : 0.0007881687488406897\n",
      "Batch : 1280, Loss : 0.0007061462383717299\n",
      "Batch : 1290, Loss : 0.0014834183966740966\n",
      "Batch : 1300, Loss : 0.006971238646656275\n",
      "Batch : 1310, Loss : 0.07916543632745743\n",
      "Batch : 1320, Loss : 0.0017094190698117018\n",
      "Batch : 1330, Loss : 0.0006331293843686581\n",
      "Batch : 1340, Loss : 0.334214985370636\n",
      "Batch : 1350, Loss : 0.001528991269879043\n",
      "Batch : 1360, Loss : 0.02417636476457119\n",
      "Batch : 1370, Loss : 3.370598278706893e-05\n",
      "Batch : 1380, Loss : 0.003631655126810074\n",
      "Batch : 1390, Loss : 0.006975024472922087\n",
      "Batch : 1400, Loss : 0.11333268135786057\n",
      "Batch : 1410, Loss : 0.000540003995411098\n",
      "Batch : 1420, Loss : 0.00039321783697232604\n",
      "Batch : 1430, Loss : 0.00042388809379190207\n",
      "Batch : 1440, Loss : 0.0005857747746631503\n",
      "Batch : 1450, Loss : 0.14005593955516815\n",
      "Batch : 1460, Loss : 0.0006861287401989102\n",
      "Batch : 1470, Loss : 0.028588401153683662\n",
      "Batch : 1480, Loss : 0.01017401460558176\n",
      "Batch : 1490, Loss : 0.0009190476848743856\n",
      "Batch : 1500, Loss : 0.00014469670713879168\n",
      "Batch : 1510, Loss : 0.05500490218400955\n",
      "Batch : 1520, Loss : 0.0011159996502101421\n",
      "Batch : 1530, Loss : 0.00037791498471051455\n",
      "Batch : 1540, Loss : 0.21033447980880737\n",
      "Batch : 1550, Loss : 0.00019252988568041474\n",
      "Batch : 1560, Loss : 0.0029397420585155487\n",
      "Batch : 1570, Loss : 0.019321942701935768\n",
      "Batch : 1580, Loss : 0.011078440584242344\n",
      "Batch : 1590, Loss : 1.6726314697734779e-06\n",
      "Batch : 1600, Loss : 0.0007357286522164941\n",
      "Batch : 1610, Loss : 0.1745067536830902\n",
      "Batch : 1620, Loss : 0.00015521160094067454\n",
      "Batch : 1630, Loss : 0.1954982578754425\n",
      "Batch : 1640, Loss : 0.01288691908121109\n",
      "Batch : 1650, Loss : 0.00738868210464716\n",
      "Batch : 1660, Loss : 0.009183177724480629\n",
      "Batch : 1670, Loss : 0.013333749957382679\n",
      "Batch : 1680, Loss : 0.0005437831277959049\n",
      "Batch : 1690, Loss : 0.062116462737321854\n",
      "Batch : 1700, Loss : 4.68930957140401e-05\n",
      "Batch : 1710, Loss : 0.07081692665815353\n",
      "Batch : 1720, Loss : 3.4311193303437904e-05\n",
      "Batch : 1730, Loss : 0.08935323357582092\n",
      "Batch : 1740, Loss : 0.00021486908372025937\n",
      "Batch : 1750, Loss : 0.002525401534512639\n",
      "Batch : 1760, Loss : 0.012243182398378849\n",
      "Batch : 1770, Loss : 1.4999509403423872e-05\n",
      "Batch : 1780, Loss : 7.936691690701991e-05\n",
      "Batch : 1790, Loss : 0.012360315769910812\n",
      "Batch : 1800, Loss : 0.0014158469857648015\n",
      "Batch : 1810, Loss : 0.002673823619261384\n",
      "Batch : 1820, Loss : 2.8370723157422617e-05\n",
      "Batch : 1830, Loss : 0.05456462502479553\n",
      "Batch : 1840, Loss : 0.017570722848176956\n",
      "Batch : 1850, Loss : 0.022570757195353508\n",
      "Batch : 1860, Loss : 0.33444252610206604\n",
      "Batch : 1870, Loss : 0.0007298407726921141\n",
      "Epoch : 8\n",
      "Batch : 0, Loss : 0.0918116495013237\n",
      "Batch : 10, Loss : 0.003258257871493697\n",
      "Batch : 20, Loss : 0.006880355067551136\n",
      "Batch : 30, Loss : 0.001045451033860445\n",
      "Batch : 40, Loss : 0.036661144345998764\n",
      "Batch : 50, Loss : 0.056061357259750366\n",
      "Batch : 60, Loss : 0.000648925662972033\n",
      "Batch : 70, Loss : 0.0008961225394159555\n",
      "Batch : 80, Loss : 0.00015116145368665457\n",
      "Batch : 90, Loss : 0.007035462651401758\n",
      "Batch : 100, Loss : 1.9880479158018716e-05\n",
      "Batch : 110, Loss : 0.004885392263531685\n",
      "Batch : 120, Loss : 0.00406144093722105\n",
      "Batch : 130, Loss : 8.350829739356413e-05\n",
      "Batch : 140, Loss : 0.005408850498497486\n",
      "Batch : 150, Loss : 0.0014417461352422833\n",
      "Batch : 160, Loss : 0.00015285676636267453\n",
      "Batch : 170, Loss : 8.011385943973437e-05\n",
      "Batch : 180, Loss : 6.481365562649444e-05\n",
      "Batch : 190, Loss : 0.007061706855893135\n",
      "Batch : 200, Loss : 0.0015005507739260793\n",
      "Batch : 210, Loss : 0.00015085848281159997\n",
      "Batch : 220, Loss : 0.00111853564158082\n",
      "Batch : 230, Loss : 7.51816769479774e-05\n",
      "Batch : 240, Loss : 0.0017247108044102788\n",
      "Batch : 250, Loss : 0.0007508560083806515\n",
      "Batch : 260, Loss : 0.0030727877747267485\n",
      "Batch : 270, Loss : 5.5262229579966515e-05\n",
      "Batch : 280, Loss : 0.00037140556378290057\n",
      "Batch : 290, Loss : 0.00019814723054878414\n",
      "Batch : 300, Loss : 0.0003578839241527021\n",
      "Batch : 310, Loss : 5.282904385239817e-05\n",
      "Batch : 320, Loss : 0.00747167831286788\n",
      "Batch : 330, Loss : 6.79054282954894e-05\n",
      "Batch : 340, Loss : 0.003121002111583948\n",
      "Batch : 350, Loss : 0.000908712565433234\n",
      "Batch : 360, Loss : 0.00020661999587900937\n",
      "Batch : 370, Loss : 0.0015235313912853599\n",
      "Batch : 380, Loss : 0.0008007266442291439\n",
      "Batch : 390, Loss : 0.003120283829048276\n",
      "Batch : 400, Loss : 0.00521017424762249\n",
      "Batch : 410, Loss : 5.077431706013158e-05\n",
      "Batch : 420, Loss : 0.0005883622216060758\n",
      "Batch : 430, Loss : 0.00011832920426968485\n",
      "Batch : 440, Loss : 9.833226795308292e-05\n",
      "Batch : 450, Loss : 0.00030492813675664365\n",
      "Batch : 460, Loss : 0.0028035358991473913\n",
      "Batch : 470, Loss : 0.0047630444169044495\n",
      "Batch : 480, Loss : 0.0018643494695425034\n",
      "Batch : 490, Loss : 0.07717041671276093\n",
      "Batch : 500, Loss : 9.159488399745896e-06\n",
      "Batch : 510, Loss : 0.00037926758523099124\n",
      "Batch : 520, Loss : 4.565982089843601e-05\n",
      "Batch : 530, Loss : 8.176932169590145e-05\n",
      "Batch : 540, Loss : 0.0005047983722761273\n",
      "Batch : 550, Loss : 2.20006586459931e-05\n",
      "Batch : 560, Loss : 0.0001805107167456299\n",
      "Batch : 570, Loss : 8.820520633889828e-06\n",
      "Batch : 580, Loss : 1.707926821836736e-05\n",
      "Batch : 590, Loss : 0.0003757326921913773\n",
      "Batch : 600, Loss : 0.000839724438264966\n",
      "Batch : 610, Loss : 0.0003039807779714465\n",
      "Batch : 620, Loss : 5.205371417105198e-05\n",
      "Batch : 630, Loss : 0.00022673023340757936\n",
      "Batch : 640, Loss : 0.002102140337228775\n",
      "Batch : 650, Loss : 0.0003738806408364326\n",
      "Batch : 660, Loss : 0.0006724739796482027\n",
      "Batch : 670, Loss : 0.00012218303163535893\n",
      "Batch : 680, Loss : 9.732955368235707e-05\n",
      "Batch : 690, Loss : 0.003883704310283065\n",
      "Batch : 700, Loss : 0.010322888381779194\n",
      "Batch : 710, Loss : 0.0017514131031930447\n",
      "Batch : 720, Loss : 0.0007130122394300997\n",
      "Batch : 730, Loss : 0.00021666854445356876\n",
      "Batch : 740, Loss : 0.00417401734739542\n",
      "Batch : 750, Loss : 0.012497342191636562\n",
      "Batch : 760, Loss : 0.040409497916698456\n",
      "Batch : 770, Loss : 0.012142067775130272\n",
      "Batch : 780, Loss : 0.0004001921624876559\n",
      "Batch : 790, Loss : 0.15814583003520966\n",
      "Batch : 800, Loss : 0.0006168527761474252\n",
      "Batch : 810, Loss : 0.022006643936038017\n",
      "Batch : 820, Loss : 0.0002977109106723219\n",
      "Batch : 830, Loss : 0.012504447251558304\n",
      "Batch : 840, Loss : 3.4792035876307636e-05\n",
      "Batch : 850, Loss : 0.023028485476970673\n",
      "Batch : 860, Loss : 0.14268510043621063\n",
      "Batch : 870, Loss : 0.15409089624881744\n",
      "Batch : 880, Loss : 0.010509968735277653\n",
      "Batch : 890, Loss : 2.9481265301001258e-05\n",
      "Batch : 900, Loss : 0.0009277754579670727\n",
      "Batch : 910, Loss : 0.002510395832359791\n",
      "Batch : 920, Loss : 0.0035737305879592896\n",
      "Batch : 930, Loss : 0.0008971919305622578\n",
      "Batch : 940, Loss : 0.0016632309416309\n",
      "Batch : 950, Loss : 0.030209660530090332\n",
      "Batch : 960, Loss : 0.011041320860385895\n",
      "Batch : 970, Loss : 0.006323729641735554\n",
      "Batch : 980, Loss : 3.9103768358472735e-05\n",
      "Batch : 990, Loss : 0.0009077176218852401\n",
      "Batch : 1000, Loss : 0.0035153322387486696\n",
      "Batch : 1010, Loss : 0.10387181490659714\n",
      "Batch : 1020, Loss : 0.00048246714868582785\n",
      "Batch : 1030, Loss : 0.008503164164721966\n",
      "Batch : 1040, Loss : 0.0055255950428545475\n",
      "Batch : 1050, Loss : 0.0010436347220093012\n",
      "Batch : 1060, Loss : 7.813033880665898e-05\n",
      "Batch : 1070, Loss : 0.011899067088961601\n",
      "Batch : 1080, Loss : 0.0007305052713491023\n",
      "Batch : 1090, Loss : 0.0001061584844137542\n",
      "Batch : 1100, Loss : 0.01115114800632\n",
      "Batch : 1110, Loss : 0.007619448006153107\n",
      "Batch : 1120, Loss : 0.0002319781924597919\n",
      "Batch : 1130, Loss : 0.028940970078110695\n",
      "Batch : 1140, Loss : 0.12813164293766022\n",
      "Batch : 1150, Loss : 0.00011446629650890827\n",
      "Batch : 1160, Loss : 0.0007306769257411361\n",
      "Batch : 1170, Loss : 0.006236125249415636\n",
      "Batch : 1180, Loss : 0.0013904416700825095\n",
      "Batch : 1190, Loss : 0.002198395086452365\n",
      "Batch : 1200, Loss : 0.001608546357601881\n",
      "Batch : 1210, Loss : 0.0033369548618793488\n",
      "Batch : 1220, Loss : 4.896216341876425e-05\n",
      "Batch : 1230, Loss : 4.7122943215072155e-05\n",
      "Batch : 1240, Loss : 0.0014018983347341418\n",
      "Batch : 1250, Loss : 0.1258900761604309\n",
      "Batch : 1260, Loss : 0.021945441141724586\n",
      "Batch : 1270, Loss : 0.006606371141970158\n",
      "Batch : 1280, Loss : 0.0001216995733557269\n",
      "Batch : 1290, Loss : 0.0021693550515919924\n",
      "Batch : 1300, Loss : 0.00044795527355745435\n",
      "Batch : 1310, Loss : 0.0004579527012538165\n",
      "Batch : 1320, Loss : 0.0015697730705142021\n",
      "Batch : 1330, Loss : 5.077390596852638e-06\n",
      "Batch : 1340, Loss : 0.006060146261006594\n",
      "Batch : 1350, Loss : 0.00028177493368275464\n",
      "Batch : 1360, Loss : 0.0009704452240839601\n",
      "Batch : 1370, Loss : 0.04988320916891098\n",
      "Batch : 1380, Loss : 0.013431088998913765\n",
      "Batch : 1390, Loss : 0.003239648649469018\n",
      "Batch : 1400, Loss : 0.000616244156844914\n",
      "Batch : 1410, Loss : 3.196238367308979e-06\n",
      "Batch : 1420, Loss : 0.00048713997239246964\n",
      "Batch : 1430, Loss : 0.0006495541310869157\n",
      "Batch : 1440, Loss : 0.005779649131000042\n",
      "Batch : 1450, Loss : 0.030796924605965614\n",
      "Batch : 1460, Loss : 0.037464678287506104\n",
      "Batch : 1470, Loss : 0.0010704509913921356\n",
      "Batch : 1480, Loss : 0.0043045817874372005\n",
      "Batch : 1490, Loss : 0.0005916217342019081\n",
      "Batch : 1500, Loss : 0.07966870069503784\n",
      "Batch : 1510, Loss : 0.0531751774251461\n",
      "Batch : 1520, Loss : 0.0005079578259028494\n",
      "Batch : 1530, Loss : 0.011748533695936203\n",
      "Batch : 1540, Loss : 0.1913052350282669\n",
      "Batch : 1550, Loss : 0.0007521907100453973\n",
      "Batch : 1560, Loss : 0.2075376808643341\n",
      "Batch : 1570, Loss : 0.0016863616183400154\n",
      "Batch : 1580, Loss : 0.0012258547358214855\n",
      "Batch : 1590, Loss : 0.008398295380175114\n",
      "Batch : 1600, Loss : 0.0019468717509880662\n",
      "Batch : 1610, Loss : 0.0005930073093622923\n",
      "Batch : 1620, Loss : 0.00015376121154986322\n",
      "Batch : 1630, Loss : 0.0016265212325379252\n",
      "Batch : 1640, Loss : 0.0168782789260149\n",
      "Batch : 1650, Loss : 0.0008159021381288767\n",
      "Batch : 1660, Loss : 0.05326174944639206\n",
      "Batch : 1670, Loss : 0.00858339574187994\n",
      "Batch : 1680, Loss : 0.003916528541594744\n",
      "Batch : 1690, Loss : 0.012102101929485798\n",
      "Batch : 1700, Loss : 0.003077479312196374\n",
      "Batch : 1710, Loss : 6.459413270931691e-05\n",
      "Batch : 1720, Loss : 0.0020062224939465523\n",
      "Batch : 1730, Loss : 0.006125038955360651\n",
      "Batch : 1740, Loss : 0.0003577207389753312\n",
      "Batch : 1750, Loss : 0.00025459800963290036\n",
      "Batch : 1760, Loss : 0.0065265921875834465\n",
      "Batch : 1770, Loss : 0.03965898975729942\n",
      "Batch : 1780, Loss : 0.0004547421704046428\n",
      "Batch : 1790, Loss : 0.0011371842119842768\n",
      "Batch : 1800, Loss : 0.42339229583740234\n",
      "Batch : 1810, Loss : 0.0020248210057616234\n",
      "Batch : 1820, Loss : 0.00585563387721777\n",
      "Batch : 1830, Loss : 0.08422526717185974\n",
      "Batch : 1840, Loss : 0.000299290957627818\n",
      "Batch : 1850, Loss : 0.0001914498716359958\n",
      "Batch : 1860, Loss : 5.043006967753172e-05\n",
      "Batch : 1870, Loss : 0.016125118359923363\n",
      "Epoch : 9\n"
     ]
    }
   ],
   "source": [
    "# 학습 실행\n",
    "\n",
    "for epoch in range(10):\n",
    "    train(model, train_loader, optimizer) \n",
    "    print(f\"Epoch : {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch : 0, Loss : 0.0018219816265627742\n",
      "Batch : 300, Loss : 8.903377306523907e-07\n",
      "Batch : 600, Loss : 0.0006543801864609122\n",
      "Batch : 900, Loss : 0.013878362253308296\n",
      "Batch : 1200, Loss : 0.0002619125007186085\n",
      "Batch : 1500, Loss : 4.65810953755863e-05\n",
      "Batch : 1800, Loss : 0.0020407382398843765\n",
      "Epoch : 1,Loss : 0.09409048724945478, Accuracy : 0.9818\n",
      "Batch : 0, Loss : 0.0007513491436839104\n",
      "Batch : 300, Loss : 1.739691697366652e-06\n",
      "Batch : 600, Loss : 2.280044100189116e-05\n",
      "Batch : 900, Loss : 1.359184261673363e-05\n",
      "Batch : 1200, Loss : 7.513464879593812e-06\n",
      "Batch : 1500, Loss : 0.0020486980210989714\n",
      "Batch : 1800, Loss : 0.055650874972343445\n",
      "Epoch : 2,Loss : 0.09745687970563136, Accuracy : 0.9789\n",
      "Batch : 0, Loss : 0.0024067761842161417\n",
      "Batch : 300, Loss : 4.95124222652521e-05\n",
      "Batch : 600, Loss : 0.00044819802860729396\n",
      "Batch : 900, Loss : 0.00019656532094813883\n",
      "Batch : 1200, Loss : 9.728407894726843e-05\n",
      "Batch : 1500, Loss : 0.00010791745444294065\n",
      "Batch : 1800, Loss : 6.7574505919765215e-06\n",
      "Epoch : 3,Loss : 0.11815092304186783, Accuracy : 0.9775\n",
      "Batch : 0, Loss : 4.788350634044036e-05\n",
      "Batch : 300, Loss : 0.0926341563463211\n",
      "Batch : 600, Loss : 7.06442297087051e-05\n",
      "Batch : 900, Loss : 0.038207653909921646\n",
      "Batch : 1200, Loss : 0.0006333547062240541\n",
      "Batch : 1500, Loss : 7.368181104538962e-05\n",
      "Batch : 1800, Loss : 0.0016835345886647701\n",
      "Epoch : 4,Loss : 0.100326423140402, Accuracy : 0.9816\n",
      "Batch : 0, Loss : 0.0005955493543297052\n",
      "Batch : 300, Loss : 1.9967226762673818e-05\n",
      "Batch : 600, Loss : 1.6316440678565414e-06\n",
      "Batch : 900, Loss : 9.3506409029942e-05\n",
      "Batch : 1200, Loss : 0.0001248245098395273\n",
      "Batch : 1500, Loss : 0.00047540568630211055\n",
      "Batch : 1800, Loss : 0.00980648584663868\n",
      "Epoch : 5,Loss : 0.13940966820767392, Accuracy : 0.9782\n",
      "Batch : 0, Loss : 4.567016731016338e-06\n",
      "Batch : 300, Loss : 0.060548264533281326\n",
      "Batch : 600, Loss : 0.0037531848065555096\n",
      "Batch : 900, Loss : 0.18760959804058075\n",
      "Batch : 1200, Loss : 0.08331474661827087\n",
      "Batch : 1500, Loss : 0.07099216431379318\n",
      "Batch : 1800, Loss : 0.1340460628271103\n",
      "Epoch : 6,Loss : 0.11856356245733721, Accuracy : 0.982\n",
      "Batch : 0, Loss : 5.278110984363593e-05\n",
      "Batch : 300, Loss : 4.6938441755628446e-07\n",
      "Batch : 600, Loss : 1.2320969290158246e-05\n",
      "Batch : 900, Loss : 0.00019608321599662304\n",
      "Batch : 1200, Loss : 0.00023561342095490545\n",
      "Batch : 1500, Loss : 6.51241498417221e-05\n",
      "Batch : 1800, Loss : 0.0715620294213295\n",
      "Epoch : 7,Loss : 0.11595682380403552, Accuracy : 0.981\n",
      "Batch : 0, Loss : 7.267748878803104e-05\n",
      "Batch : 300, Loss : 5.438887455966324e-07\n",
      "Batch : 600, Loss : 0.0491914339363575\n",
      "Batch : 900, Loss : 5.92588257859461e-05\n",
      "Batch : 1200, Loss : 0.002473965287208557\n",
      "Batch : 1500, Loss : 0.002651904709637165\n",
      "Batch : 1800, Loss : 3.806912718573585e-05\n",
      "Epoch : 8,Loss : 0.11461078687693843, Accuracy : 0.984\n",
      "Batch : 0, Loss : 0.0001804660278139636\n",
      "Batch : 300, Loss : 9.313217219641956e-08\n",
      "Batch : 600, Loss : 0.009274418465793133\n",
      "Batch : 900, Loss : 0.04087943956255913\n",
      "Batch : 1200, Loss : 0.0002227956720162183\n",
      "Batch : 1500, Loss : 3.51286917066318e-06\n",
      "Batch : 1800, Loss : 0.004815211053937674\n",
      "Epoch : 9,Loss : 0.13312657815260262, Accuracy : 0.98\n",
      "Batch : 0, Loss : 1.3200341527408455e-05\n",
      "Batch : 300, Loss : 0.0030245319940149784\n",
      "Batch : 600, Loss : 2.644950427566073e-07\n",
      "Batch : 900, Loss : 6.854506864328869e-07\n",
      "Batch : 1200, Loss : 7.4505797087454084e-09\n",
      "Batch : 1500, Loss : 2.8021571779390797e-05\n",
      "Batch : 1800, Loss : 6.803541327826679e-05\n",
      "Epoch : 10,Loss : 0.13539864789295097, Accuracy : 0.9812\n"
     ]
    }
   ],
   "source": [
    "# 학습 실행 2 \n",
    "\n",
    "for epoch in range(10):\n",
    "    train(model, train_loader, optimizer) \n",
    "    loss, accuracy = evaluate(model, test_loader)\n",
    "    print(f\"Epoch : {epoch + 1}, Loss : {loss}, Accuracy : {accuracy}\")\n",
    "    # 에폭마다 validation이 어떻게 개선되는지 볼 수 있게 함. (여기선 validation따로 안 만들어서 test로 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13539811854153214, 0.9812)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최정적인 작업\n",
    "evaluate(model, test_loader)\n",
    "# (0.10986950756961578, 정확도 : 0.9776)\n",
    "# (0.13539811854153214, 0.9812)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-dl-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
